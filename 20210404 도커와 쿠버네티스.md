---
date: 2021.04.04
title: 도커와 쿠버네티스
tag: 클라우드, 도커, 쿠버네티스
---

# 도커와 쿠버네티스

## 클라우드

아래의 아마존 AWS의 클라우드 컴퓨팅에 대한 설명과, [vanshvarshney](https://medium.com/@vanshvarshney_/what-is-iaas-vs-saas-vs-paas-and-xaas-whats-the-difference-examples-ceadeee146e6)의 그림을 참고하자.

> 클라우드 컴퓨팅은 IT 리소스를 인터넷을 통해 온디맨드로 제공하고 사용한 만큼만 비용을 지불하는 것을 말합니다. **물리적 데이터 센터와 서버를 구입, 소유 및 유지 관리하는 대신, Amazon Web Services(AWS)와 같은 클라우드 공급자로부터 필요에 따라 컴퓨팅 파워, 스토리지, 데이터베이스와 같은 기술 서비스에 액세스**할 수 있습니다.
>
> 클라우드 컴퓨팅의 세 가지 주요 유형에는 **Infrastructure as a Service, Platform as a Service, Software as a Service**가 있습니다. 각 클라우드 컴퓨팅 유형은 다양한 수준의 제어, 유연성 및 관리 기능을 제공하므로 필요에 맞는 서비스 세트를 선택할 수 있습니다. [출처](https://aws.amazon.com/ko/what-is-cloud-computing/)

![img](https://miro.medium.com/max/1376/1*e331LS_mfpebxC9KklCttQ.png)

#### 문서 살펴보기

##### 알리바바 클라우드 문서

- [클라우드 컴퓨팅이란 무엇인가요?](https://www.alibabacloud.com/ko/knowledge/what-is-cloud-computing?spm=a3c0i.249142.4012599670.4.46f7159f7IejMs) - 인터넷을 통해 컴퓨팅 리소스를 종량제 방식으로 사용하는 것
- [퍼블릭 클라우드란 무엇인가요?](https://www.alibabacloud.com/ko/knowledge/what-is-public-cloud?spm=a3c0i.249107.9931382400.4.1d554457B09USv) - 인터넷을 통해 접근할 수 있는 클라우드
- [프라이빗 클라우드란 무엇인가요?](https://www.alibabacloud.com/ko/knowledge/what-is-private-cloud?spm=a3c0i.249123.9442291580.6.5a7c6bf5tvoSo8) - 온프레미스(내부 프라이빗), 퍼블릭 가상 격리 및 VPN(가상 프라이빗)
- [가상화란 무엇인가요?](https://www.alibabacloud.com/ko/knowledge/what-is-virtualization?spm=a3c0i.249160.6261847050.6.334a4d7dl4gJQb) - 클라우드에서 가상화는 물리적 머신에 가상 머신을 두는 하드웨어 가상화를 의미...?
- [하이퍼바이저란 무엇인가요?](https://www.alibabacloud.com/ko/knowledge/what-is-hypervisor) - 물리적 머신을 가상 머신으로 분할해주는 소프트웨어

## 가상화

가상화 기술의 종류는 다양하다. 자세한 것은 차차 알아보기로 하고 VMware 처럼 게스트OS를 사용하는 방식과 Docker 처럼 컨테이너를 사용하는 방식이 있다는 것 정도만 알아두자. 참고로 하이퍼바이저란 물리적 머신을 다수의 가상 머신으로 분할해주는 역할을 한다.

#### 하이퍼바이저 방식의 가상화

- 타입1(베어메탈방식) : Xen, KVM
- 타입2(호스트방식) : VMware, VirtualBox

#### 컨테이너 방식의 가상화

- Docker
- Podman
- Kubernetes

☞ 여기서 잠깐! 컨테이너에 대해 찾다보면 도커와 쿠버네티스라는 말을 자주 볼 수 있는데, 둘은 역할이 다르다. 도커는 컨테이너 이미지를 만들고 실행하는 역할을 한다. 쿠버네티스는 이러한 컨테이너를 수백, 수천 개 이상 운용해야 할 때 이들을 적절한 서버에 할당하고 장애에 대응하는 등 이들을 자동 관리하는 기능을 한다. 쿠버네티스는 도커 스웜이나 아파치 mesos에 비교할 수 있다.

## 도커

#### 컨테이너, 이미지 요약

##### 컨테이너

- 컨테이너화 : 애플리케이션, 서비스, 종속성, 구성 등을 컨테이너 이미지로 패키징하는 개발 방법
- 장점 : 이식성(수정 없이 배포), 민첩성(VM이미지보다 작음), 확장성(추가 컨테이너 생성), 환경 격리, 제어
- 컨테이너 : 이미지를 실행한 인스턴스(프로세스)
- 이미지 : 컨테이너를 만들기 위한 템플릿(파일 시스템)
- 컨테이너 레이어 : 컨테이너 생성 시 추가되는 최상단의 쓰기 가능 레이어. 컨테이너 제거 시 삭제됨. 볼륨과 다름.

##### 이미지

- 개요 : 도커 컨테이너를 만들기 위한 명령어를 가진 읽기 전용 템플릿
- 구성 : 컨테이너에서 사용할 격리된 파일 시스템, 애플리케이션을 실행하는 데 필요한 모든 항목(모든 종속성, 구성, 스크립트, 실행파일 등), 컨테이너에 대한 다른 구성(예 : 환경 변수, 실행할 기본 명령, 기타 메타데이터)
- 빌드 : Dockefile로 정의한 단계에 따라 이미지를 생성. 다른 이미지(예:우분투)를 기반으로 사용자 정의 요소(예:웹서버,애플리케이션,기타구성요소)를 추가 가능.
- 이미지 레이어 : 이미지는 일련의 레이어로 구성. 각 레이어는 Dockerfile의 명령어에 해당. 이전 레이어와의 차이점(델타). 컨테이너 레이어를 제외한 모든 레이어는 읽기 전용. 재빌드 시 변경 레이어만 빌드.

#### 문서 살펴보기

##### 마이크로소프트 문서

- [기초 개념 : 컨테이너 및 Docker 소개](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/container-docker-introduction/)
- [주요 용어 : Docker 용어](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/container-docker-introduction/docker-terminology)
- [마이크로 서비스 설계 : 컨테이너 및 마이크로 서비스 기반 애플리케이션 설계](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/architect-microservice-container-applications/)
- [데이터 저장 : Docker 애플리케이션의 상태 및 데이터](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/architect-microservice-container-applications/docker-application-state-data)
- [전체적인 개발 워크플로 : Docker 앱에 대한 개발 워크플로](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/docker-application-development-process/docker-app-development-workflow)
- [핵심 내용](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/key-takeaways)
- [시작](https://docs.microsoft.com/ko-kr/visualstudio/docker/tutorials/docker-tutorial)

> 컨테이너화는 **애플리케이션 또는 서비스, 이에 해당하는 종속성 및 (배포 매니페스트 파일로 일반화된) 구성이 컨테이너 이미지로 패키지되는 소프트웨어 개발 방법**입니다. 컨테이너화된 애플리케이션은 하나의 단위로 테스트하고 컨테이너 이미지 인스턴스로 호스트 OS(운영 체제)에 배포할 수 있습니다.
>
> 배송 컨테이너를 사용하여 컨테이너 안에 들어있는 화물에 상관없이 상품을 배, 기차 또는 트럭으로 운반하듯이 소프트웨어 컨테이너도 다양한 코드 및 종속성을 포함할 수 있는 소프트웨어 배포의 표준 단위 역할을 합니다. 이러한 방식의 **소프트웨어 컨테이너화를 통해 개발자와 IT 전문가는 수정 과정을 거의 거치지 않고 모든 환경에서 응용 프로그램을 배포**할 수 있습니다.
>
> 또한 컨테이너는 **공유 OS에서 애플리케이션을 서로 격리**합니다. 컨테이너화된 애플리케이션은 OS(Linux 또는 Windows)에서 차례대로 실행되는 컨테이너 호스트의 맨 위에서 실행됩니다. 따라서 **컨테이너의 공간은 VM(가상 머신) 이미지보다 훨씬 작습니다**.
>
> **컨테이너화의 또 다른 이점은 확장성**입니다. 단기 작업에 대한 새 컨테이너를 만들어 신속하게 확장할 수 있습니다. 애플리케이션의 관점에서 볼 때 이미지 인스턴스화(컨테이너 생성)는 서비스 또는 웹앱과 같은 프로세스 인스턴스화와 비슷합니다. 그러나 안정성을 생각한다면, 동일한 이미지의 여러 인스턴스를 여러 호스트 서버에서 실행할 경우 일반적으로 기본 도메인이 다른 다양한 호스트 서버 또는 VM에서 각 컨테이너(이미지 인스턴스)를 실행하려 할 것입니다.
>
> 즉, 컨테이너는 전체 애플리케이션 수명 주기 워크플로에서 격리, 이식성, 민첩성, 확장성, 제어에 대한 이점이 있습니다. 가장 중요한 이점은 개발 및 작업 사이에서 **환경 격리를 제공**한다는 것입니다. [출처](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/container-docker-introduction/)

> **컨테이너 이미지**: 컨테이너를 만드는 데 필요한 모든 종속성 및 정보를 포함한 패키지입니다. 이미지에는 모든 종속성(예: 프레임워크) 및 컨테이너 런타임에서 사용할 배포 및 실행 구성이 포함됩니다. 일반적으로 이미지는 컨테이너의 파일 시스템을 구성하기 위해 계층으로 서로 포개진 여러 개의 기본 이미지에서 파생됩니다. 이미지를 만들면 변경할 수 없습니다.
>
> **Dockerfile**: Docker 이미지를 빌드하기 위한 지침을 포함하는 텍스트 파일입니다. 배치 스크립트처럼 첫 번째 줄에 지정된 기본 이미지에서 시작한 다음, 필요한 작업 환경이 완성될 때까지 지침에 따라 필요한 프로그램을 설치하고 파일을 복사하는 등의 작업을 수행합니다.
>
> **빌드:** 해당 Dockerfile에서 제공하는 정보 및 컨텍스트에 외에도 이미지를 빌드하는 폴더의 추가 파일에 기반하여 컨테이너 이미지를 빌드하는 작업입니다. 다음의 Docker 명령을 사용하여 이미지를 빌드할 수 있습니다. `docker build`
>
> **컨테이너**: Docker 이미지의 인스턴스입니다. 컨테이너는 단일 애플리케이션, 프로세스 또는 서비스의 실행을 나타냅니다. Docker 이미지의 콘텐츠, 실행 환경 및 명령의 표준 집합으로 구성됩니다. 서비스의 크기를 조정하는 경우 동일한 이미지에서 컨테이너의 여러 인스턴스를 만듭니다. 일괄 작업은 동일한 이미지에서 다중 컨테이너를 만들 수 있고 각 인스턴스에 다른 매개 변수를 전달합니다.
>
> **볼륨**: 컨테이너가 사용할 수 있는 쓰기 가능한 파일 시스템을 제공합니다. 이미지는 읽기 전용이지만 대부분의 프로그램이 파일 시스템에 써야 하기 때문에 볼륨은 컨테이너 이미지의 맨 위에 쓰기 가능한 계층을 추가하여 프로그램이 쓰기 가능한 파일 시스템에 액세스할 수 있도록 합니다. 프로그램은 계층화된 파일 시스템에 액세스하는 것을 알지 못하며, 단순히 일반적인 파일 시스템입니다. 볼륨은 호스트 시스템에 있으며 Docker에 의해 관리됩니다.
>
> **태그**: (버전 번호 또는 대상 환경에 따라) 다양한 이미지 또는 동일한 이미지의 버전을 식별할 수 있도록 표시 또는 레이블은 이미지에 적용할 수 있습니다.
>
> **다단계 빌드**: 최종 이미지의 크기를 줄이는 데 도움이 되는 Docker 17.05 이상의 기능입니다. 일부 문장에서는 다단계 빌드를 통해 애플리케이션을 컴파일 및 게시하기 위한 SDK가 포함된 큰 기본 이미지를 사용한 후 작은 런타임 전용 기본 이미지가 포함된 게시 폴더를 사용하여 훨씬 작은 최종 이미지를 생성할 수 있습니다.
>
> **리포지토리**: 이미지 버전을 나타내는 태그를 사용하여 이미지가 지정된 관련 Docker 이미지의 컬렉션입니다. 일부 리포지토리에는 SDK를 포함하는 이미지(무거움), 런타임(가벼움)만을 포함하는 이미지 등 특정 이미지의 여러 변형이 포함됩니다. 이러한 변형은 태그로 표시할 수 있습니다. 단일 리포지토리는 Linux 이미지 및 Windows 이미지 같은 플랫폼 변형을 포함할 수 있습니다.
>
> **레지스트리**: 리포지토리에 대한 액세스를 제공하는 서비스입니다. 대부분의 공용 이미지에 대한 기본 레지스트리는 Docker 허브(조직인 Docker에서 소유함)입니다. 레지스트리는 일반적으로 여러 팀의 리포지토리를 포함합니다. 회사에는 대체로 만든 이미지를 저장하고 관리하기 위한 개인 레지스트리가 있습니다. Azure Container Registry는 또 다른 예입니다.
>
> **다중 아키텍처 이미지**: 다중 아키텍처에서 Docker가 실행되는 플랫폼에 따라 적절한 이미지 선택을 간소화하는 기능입니다. 예를 들어, Dockerfile이 레지스트리에서 기본 이미지 mcr.microsoft.com/dotnet/sdk:5.0 을 요청하는 경우 Docker가 실행되는 운영 체제 및 버전에 따라 5.0-nanoserver-1909, 5.0-nanoserver-1809 또는 5.0-buster-slim 을 실제로 가져옵니다.
>
> **Docker 허브**: 이미지를 업로드하고 여기에서 작업하는 공개 레지스트리입니다. Docker 허브는 Docker 이미지 호스팅, 공개 또는 개인 레지스트리, 빌드 트리거 및 웹후크, GitHub 및 Bitbucket과 통합을 제공합니다.
>
> **Azure Container Registry**: Docker 이미지로 작업하는 공용 리소스 및 Azure의 해당 구성 요소입니다. 여기서는 Azure에서 배포에 가깝고, 액세스에 대한 제어를 제공하는 레지스트리를 제공하여 Azure Active Directory 그룹 및 권한을 사용할 수 있도록 합니다.
>
> **DTR(Docker Trusted Registry)** : 조직의 데이터 센터 및 네트워크 내에서 유지되도록 온-프레미스에 설치될 수 있는 Docker의 Docker 레지스트리 서비스입니다. 엔터프라이즈 내에서 관리되어야 하는 프라이빗 이미지에 유용합니다. Docker Trusted Registry는 Docker 데이터 센터 제품의 일부로 포함됩니다. 자세한 내용은 DTR(Docker Trusted Registry)를 참조하세요.
>
> **Docker CE(Community Edition)** : 로컬로 컨테이너를 빌드하고, 실행하고, 테스트하는 Windows 및 macOS용 개발 도구입니다. Windows용 Docker CE는 Linux 및 Windows 컨테이너에 개발 환경을 제공합니다. Windows의 Linux Docker 호스트는 Hyper-V 가상 머신을 기반으로 합니다. Windows 컨테이너에 대한 호스트는 Windows를 직접 기반으로 합니다. Mac용 Docker CE는 Apple 하이퍼바이저 프레임워크 및 xhyve 하이퍼바이저를 기반으로 하며 macOS X에서 Linux Docker 호스트 가상 머신을 제공합니다. Windows 및 Mac용 Docker CE는 Oracle VirtualBox를 기반으로 하던 Docker 도구 상자를 대체합니다.
>
> **Docker EE(Enterprise Edition)** : Linux 및 Windows 개발을 위한 엔터프라이즈급 버전의 Docker 도구입니다.
>
> **작성**: 다중 컨테이너 애플리케이션을 정의하고 실행하는 데 메타데이터를 사용하는 명령줄 도구 및 YAML 파일 형식입니다. 환경에 따라 값을 재정의할 수 있는 하나 이상의 .yml 파일을 사용하여 여러 이미지를 기반으로 하는 단일 애플리케이션을 정의합니다. 정의를 만든 후에 Docker 호스트에 이미지당 컨테이너를 만드는 단일 명령(docker-compose up)을 사용하여 전체 다중 컨테이너 애플리케이션을 배포할 수 있습니다.
>
> **클러스터**: 애플리케이션이 클러스터 내의 여러 호스트에 걸쳐 분산된 서비스의 여러 인스턴스 크기를 조정할 수 있도록 단일 가상 Docker 호스트인 것처럼 노출된 Docker 호스트 컬렉션입니다. Docker 클러스터는 Kubernetes, Azure Service Fabric, Docker Swarm 및 Mesosphere DC/OS를 사용하여 만들 수 있습니다.
>
> **오케스트레이터**: 클러스터 및 Docker 호스트의 관리를 간소화하는 도구입니다. 오케스트레이터를 사용하면 CLI(명령줄 인터페이스)또는 그래픽 UI를 통해 해당 이미지, 컨테이너 및 호스트를 관리할 수 있습니다. 컨테이너 네트워킹, 구성, 부하 분산, 서비스 검색, 고가용성, Docker 호스트 구성 등을 관리할 수 있습니다. 오케스트레이터는 노드 컬렉션 간에 워크로드를 실행하고, 배포하고, 크기를 조정하고. 복구하는 작업을 담당합니다. 일반적으로 오케스트레이터 제품은 출시된 다른 제품 중에서 Kubernetes 및 Azure Service Fabric과 같은 클러스터 인프라를 제공하는 동일한 제품입니다. [출처](https://docs.microsoft.com/ko-kr/dotnet/architecture/microservices/container-docker-introduction/docker-terminology)

##### 도커 문서

- [Docker 개요](https://docs.docker.com/get-started/overview/)
- [Docker 시작하기](https://docs.docker.com/get-started/)
- [Dockerfile 작성을 위한 모범 사례](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)
- [스토리지 드라이버 정보](https://docs.docker.com/storage/storagedriver/)

> 컨테이너를 실행할 때 격리 된 파일 시스템을 사용합니다. 이 사용자 정의 파일 시스템은 컨테이너 이미지에서 제공합니다. **이미지에는 컨테이너의 파일 시스템이 포함**되므로, **애플리케이션을 실행하는 데 필요한 모든 항목(모든 종속성, 구성, 스크립트, 실행파일 등)이 포함**되어야 합니다. 이미지에는 **컨테이너에 대한 다른 구성 (예 : 환경 변수, 실행할 기본 명령, 기타 메타데이터)도 포함**됩니다. [출처](https://docs.docker.com/get-started/)

> 도커 컨테이너를 만들기 위한 명령어를 가진 읽기 전용 템플릿입니다. **종종 이미지는 몇 가지 추가 사용자 정의와 함께 다른 이미지를 기반**으로 합니다. 예를 들어, 우분투 이미지를 기반으로 Apache 웹 서버, 애플리케이션, 애플리케이션을 실행하는 데 필요한 구성 세부 사항을 설치하는 이미지를 빌드할 수 있습니다. [출처](https://docs.docker.com/get-started/overview/)
>
> **자신의 이미지를 만들거나 다른 사람이 만들어 레지스트리에 게시한 이미지를 사용할 수 있습니다**. 고유한 이미지를 빌드하려면 이미지를 만들고 실행하는 데 필요한 단계를 정의하는 간단한 구문으로 Dockerfile 을 만듭니다. **Dockerfile의 각 명령어는 이미지에 레이어를 만듭니다**. **Dockerfile을 변경하고 이미지를 다시 빌드하면 변경된 레이어만 다시 빌드됩니다.** 이것은 다른 가상화 기술과 비교할 때 이미지를 매우 가볍고, 작고, 빠르게 만드는 요소의 일부입니다. [출처](https://docs.docker.com/get-started/overview/)

> 간단히 말해 컨테이너는 **호스트 시스템의 다른 모든 프로세스와 격리된 시스템의 또 다른 프로세스**입니다. 이러한 격리는 오랫동안 Linux에 있었던 기능인 커널 네임 스페이스와 cgroup을 활용합니다 . Docker는 이러한 기능을 접근하기 쉽고 사용하기 쉽게 만들기 위해 노력했습니다. [출처](https://docs.docker.com/get-started/)

> **컨테이너는 이미지의 실행 가능한 인스턴스**입니다. Docker API 또는 CLI를 사용하여 컨테이너를 생성, 시작, 중지, 이동 또는 삭제할 수 있습니다. **컨테이너를 하나 이상의 네트워크에 연결하거나, 스토리지를 연결하거나 현재 상태를 기반으로 새 이미지를 만들 수**도 있습니다.
>
> 기본적으로 **컨테이너는 다른 컨테이너 및 호스트 시스템과 비교적 잘 격리**되어 있습니다. 컨테이너의 네트워크, 스토리지 또는 기타 기본 하위 시스템이 다른 컨테이너 또는 호스트 시스템에서 **분리되는 방식을 제어 할 수** 있습니다.
>
> **컨테이너는 이미지와 사용자가 생성하거나 시작할 때 제공하는 구성 옵션과 이미지에 의해 정의**됩니다. **컨테이너가 제거되면 영구 저장소에 저장되지 않은 상태 변경 사항이 사라집니다**. [출처](https://docs.docker.com/get-started/overview/)

> 컨테이너와 이미지의 주요 차이점은 쓰기 가능한 최상위 레이어입니다. **새 데이터를 추가하거나 기존 데이터를 수정하는 컨테이너에 대한 모든 쓰기는 이 쓰기 가능한 레이어에 저장**됩니다. **컨테이너가 삭제되면 쓰기 가능한 레이어도 삭제**됩니다. 기본 이미지는 변경되지 않습니다.
>
> **각 컨테이너에는 자체 쓰기 가능한 컨테이너 계층**이 있고 모든 변경 사항이 이 컨테이너 계층에 저장되기 때문에 **여러 컨테이너가 동일한 기본 이미지에 대한 액세스를 공유하면서도 자체 데이터 상태를 가질 수** 있습니다. [출처](https://docs.docker.com/storage/storagedriver/)

> Docker 이미지는 **각각 Dockerfile 명령어를 나타내는 읽기 전용 레이어로 구성**됩니다. 레이어는 쌓여 있고 각 레이어는 이전 레이어의 변경 사항에 대한 델타입니다. [출처](https://docs.docker.com/storage/storagedriver/)

> Docker 이미지는 일련의 레이어로 구성됩니다. 각 계층은 이미지의 Dockerfile에 있는 명령을 나타냅니다. **마지막 레이어를 제외한 각 레이어는 읽기 전용**입니다. [출처](https://docs.docker.com/storage/storagedriver/)

> **각 레이어는 이전 레이어와의 차이점 집합** 일뿐입니다. 레이어는 서로 겹쳐집니다. **새 컨테이너를 만들 때 기본 레이어 위에 새 쓰기 가능한 레이어를 추가**합니다. 이 레이어를 종종 "컨테이너 레이어"라고합니다. 새 파일 쓰기, 기존 파일 수정 및 파일 삭제와 같이 **실행중인 컨테이너에 대한 모든 변경 사항은 이 쓰기 가능한 컨테이너 계층에 기록**됩니다. [출처](https://docs.docker.com/storage/storagedriver/)

> 컨테이너는 파일을 생성, 업데이트 및 삭제할 수 있지만 컨테이너가 제거되고 모든 변경 사항이 해당 컨테이너에 격리되면 이러한 변경 사항이 손실됩니다. 볼륨으로이 모든 것을 변경할 수 있습니다.
>
> 볼륨은 컨테이너의 특정 파일 시스템 경로를 호스트 시스템에 다시 연결하는 기능을 제공합니다. 컨테이너의 디렉토리가 마운트되면 해당 디렉토리의 변경 사항도 호스트 시스템에 표시됩니다. 컨테이너를 다시 시작할 때 동일한 디렉터리를 마운트하면 동일한 파일이 표시됩니다. [출처](https://docs.docker.com/get-started/05_persisting_data/#container-volumes)

##### 기타 문서

- [왜 굳이 도커(컨테이너)를 써야 하나요?](https://www.44bits.io/ko/post/why-should-i-use-docker-container)
- [도커 입문 hands-on](https://github.com/voyagerwoo/docker-hands-on)
- [도커(Docker) 입문편 - 컨테이너 기초부터 서버 배포까지](https://www.44bits.io/ko/post/easy-deploy-with-docker)
- [도커를 이용한 웹서비스 무중단 배포하기](https://subicura.com/2016/06/07/zero-downtime-docker-deployment.html)
- [[Docker\] 개념 정리 및 사용방법까지](https://cultivo-hy.github.io/docker/image/usage/2019/03/14/Docker정리/)
- [Demystifying Containers - Part I: Kernel Space](https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504)
- [[Docker 기본(5/8)\] Volume을 활용한 Data 관리](https://medium.com/dtevangelist/docker-기본-5-8-volume을-활용한-data-관리-9a9ac1db978c)

#### 기본 명령어

윈도우라면 Docker Desktop에서 GUI를 지원하지만 리눅스에서는 [기본 명령어](https://docs.docker.com/engine/reference/commandline/docker/)들을 사용해야 할 것이다.

| 명령어             | 의미                                                         |
| :----------------- | :----------------------------------------------------------- |
| docker attach      | 실행중인 컨테이너에 로컬 표준 입력, 출력 및 오류 스트림 연결 |
| **docker build**   | Dockerfile에서 이미지 빌드                                   |
| docker builder     | 빌드 관리                                                    |
| docker checkpoint  | 체크 포인트 관리                                             |
| docker commit      | 컨테이너의 변경 사항에서 새 이미지 만들기                    |
| docker config      | Docker 구성 관리                                             |
| docker container   | 컨테이너 관리                                                |
| docker context     | 컨텍스트 관리                                                |
| docker cp          | 컨테이너와 로컬 파일 시스템간에 파일 / 폴더 복사             |
| docker create      | 새 컨테이너 만들기                                           |
| docker diff        | 컨테이너의 파일 시스템에있는 파일 또는 디렉토리의 변경 사항 검사 |
| docker events      | 서버에서 실시간 이벤트 받기                                  |
| **docker exec**    | 실행중인 컨테이너에서 명령 실행                              |
| docker export      | 컨테이너의 파일 시스템을 tar 아카이브로 내보내기             |
| docker history     | 이미지의 역사보기                                            |
| docker image       | 이미지 관리                                                  |
| **docker images**  | 이미지 나열                                                  |
| docker import      | tarball에서 내용을 가져와 파일 시스템 이미지를 만듭니다.     |
| docker info        | 시스템 전체 정보 표시                                        |
| docker inspect     | Docker 객체에 대한 하위 수준 정보 반환                       |
| docker kill        | 하나 이상의 실행중인 컨테이너를 죽입니다.                    |
| docker load        | tar 아카이브 또는 STDIN에서 이미지로드                       |
| **docker login**   | Docker 레지스트리에 로그인                                   |
| docker logout      | Docker 레지스트리에서 로그 아웃                              |
| **docker logs**    | 컨테이너의 로그 가져 오기                                    |
| docker manifest    | Docker 이미지 매니페스트 및 매니페스트 목록 관리             |
| **docker network** | 네트워크 관리                                                |
| docker node        | Swarm 노드 관리                                              |
| docker pause       | 하나 이상의 컨테이너 내에서 모든 프로세스 일시 중지          |
| docker plugin      | 플러그인 관리                                                |
| docker port        | 컨테이너에 대한 포트 매핑 또는 특정 매핑 나열                |
| **docker ps**      | 컨테이너 나열                                                |
| **docker pull**    | 레지스트리에서 이미지 또는 저장소 가져 오기                  |
| **docker push**    | 이미지 또는 저장소를 레지스트리로 푸시                       |
| docker rename      | 컨테이너 이름 변경                                           |
| docker restart     | 하나 이상의 컨테이너 다시 시작                               |
| **docker rm**      | 하나 이상의 용기 제거                                        |
| **docker rmi**     | 하나 이상의 이미지 제거                                      |
| **docker run**     | 새 컨테이너에서 명령 실행                                    |
| docker save        | 하나 이상의 이미지를 tar 아카이브에 저장 (기본적으로 STDOUT으로 스트리밍) |
| docker search      | Docker Hub에서 이미지 검색                                   |
| docker secret      | Docker 비밀 관리                                             |
| docker service     | 서비스 관리                                                  |
| docker stack       | Docker 스택 관리                                             |
| **docker start**   | 하나 이상의 중지 된 컨테이너 시작                            |
| docker stats       | 컨테이너 리소스 사용 통계의 라이브 스트림 표시               |
| **docker stop**    | 하나 이상의 실행중인 컨테이너 중지                           |
| **docker swarm**   | Swarm 관리                                                   |
| **docker system**  | Docker 관리                                                  |
| **docker tag**     | SOURCE_IMAGE를 참조하는 TARGET_IMAGE 태그를 만듭니다.        |
| docker top         | 컨테이너의 실행중인 프로세스 표시                            |
| docker trust       | Docker 이미지에 대한 신뢰 관리                               |
| docker unpause     | 하나 이상의 컨테이너에있는 모든 프로세스의 일시 중지 해제    |
| docker update      | 하나 이상의 컨테이너 구성 업데이트                           |
| docker version     | Docker 버전 정보 표시                                        |
| **docker volume**  | 볼륨 관리                                                    |
| docker wait        | 하나 이상의 컨테이너가 멈출 때까지 차단 한 다음 종료 코드를 인쇄합니다. |

#### 설치

- WSL2 설치 : [Windows 10에 Linux용 Windows 하위 시스템 설치 가이드](https://docs.microsoft.com/ko-kr/windows/wsl/install-win10)
- 도커 설치 : [Windows 용 Docker Desktop](https://hub.docker.com/editions/community/docker-ce-desktop-windows)
- WSL2 설치 과정 중 가상화 관련 기능이 화면 깜빡임을 유발(AMD Ryzen 3 4300U - Windows 10 Pro)
- CMD(관리자권한)에서 다음 명령어로 필요할 때만 가상화 관련 기능을 사용

```
bcdedit /set hypervisorlaunchtype off   // 끄기 (재부팅) - 안 깜빡임. VirtualBox 설치도 가능.
bcdedit /set hypervisorlaunchtype auto  // 켜기 (재부팅) - 깜빡임...
```

- 위 방법이 불편하다면 가상화 관련 기능은 켜둔 채 IOMMU를 disable 하면 안 깜빡인다. ([참고](https://community.amd.com/t5/drivers-software/brand-new-laptop-with-ryzen-4700u-vega-10-screen-flickers/td-p/269149))

```
bcdedit /set hypervisoriommupolicy disable // Input Output Memory Management Unit ...
```

#### 도커 실습1

다음 글을 참고하였다.

- [시작하기](https://docs.docker.com/get-started/)

Docker Desktop을 실행하고 터미널에서 다음을 실행해보자.

```
docker run -d -p 80:80 docker/getting-started
```

Docker Desktop에 이미지와 컨테이너가 추가된 것을 볼 수 있다. 컨테이너의 `OPEN IN BROWSER`아이콘을 클릭하면 브라우저가 열리고 localhost/tutorial 의 Getting Started 페이지가 뜨는 것을 볼 수 있다. 무슨 일이 일어난 것인지 보자.

- docker run : 도커 이미지를 실행한다. 로컬에 도커 이미지가 없으면 원격에서 가져온다.
- -d : 분리 모드에서 컨테이너 실행 (백그라운드 모드)
- -p 80:80 : 호스트의 80포트를 도커 컨테이너의 80포트와 연결
- docker/getting-started : 도커 이미지

브라우저에 표시된 Getting Started 페이지의 내용은 [여기](https://docs.docker.com/get-started/)에서도 볼 수 있다.

#### 도커 실습2

다음 글을 참고하였다.

- [nodejs 프로젝트를 docker로 배포하기1](https://medium.com/extales/node-js-프로젝트를-docker로-배포하기-1-536e03b9b2ff)
- [nodejs 프로젝트를 docker로 배포하기2](https://medium.com/extales/node-js-프로젝트를-docker로-배포하기-2-cfff76ebae7e)
- [nodejs 프로젝트를 docker로 배포하기3](https://medium.com/extales/node-js-프로젝트를-docker로-배포하기-3-ce7cf71ce874)

##### 웹 애플리케이션 준비

이 애플리케이션을 도커 이미지로 만들고 컨테이너로 실행할 것이다.

```powershell
D:\docku2>git clone  https://github.com/smalljiny/example-docker-nodejs.git
D:\docku2>cd example-docker-nodejs
D:\docku2\example-docker-nodejs>npm install
D:\docku2\example-docker-nodejs>npm run serve
D:\docku2\example-docker-nodejs>curl localhost:8080/?name=docku # {"msg":"Hello docku!"}
```

##### 도커 이미지 빌드 준비

D:\docku2\example-docker-nodejs\.dockerignore 생성 : 빌드에서 제외할 목록

```
node_modules
```

D:\docku2\example-docker-nodejs\Dockerfile 생성 : 빌드 절차를 선언

```
FROM node:10                # 부모 이미지 지정
WORKDIR /usr/src/app        # 작업 디렉토리 생성
COPY package*.json ./       # 의존성 설치
RUN npm install             # 의존성 설치
COPY . .                    # 소스 추가
EXPOSE 8080                 # 포트 매핑
CMD [ "node", "app.js" ]    # 실행 명령
```

##### 도커 이미지 빌드

```powershell
D:\docku2\example-docker-nodejs>docker build
"docker build" requires exactly 1 argument.
See 'docker build --help'.
Usage:  docker build [OPTIONS] PATH | URL | -
Build an image from a Dockerfile # 도커 파일로부터 이미지를 빌드한다

D:\docku2\example-docker-nodejs>docker build -t mydockerimage:1.0 .
```

WSL2를 사용하는 경우 빌드한 이미지는 윈도우의 어디에 저장되는 것일까? [이 글](https://stackoverflow.com/a/63752264)을 참고하자. 요약하면...

> vm 디스크 이미지 위치 : %USERPROFILE%\AppData\Local\Docker\wsl\data\ext4.vhdx
>
> wsl --export, wsl --unregister, wsl --import 등으로 vm 디스크 이미지 위치를 변경할 수 있음

Docker Desktop에서 봤을 땐 900메가짜리 이미지라고 표시되지만 빌드하는 시간은 순식간이다. 아마도 읽기 전용 레이어에 대해서는 해당 레이어를 재활용하고 실제 사용자 애플리케이션 등이 존재하는 레이어에 대해서만 처리하는 것 같다. 게다가 애플리케이션에 수정을 가한 후 다시 빌드할 경우에도 가능한 부분은 최대한 재활용하여 빠르게 빌드하는 것 같다. (참고 : [이미지 레이어 저장방식](https://cultivo-hy.github.io/docker/image/usage/2019/03/14/Docker정리/#이미지image), [도커 이미지 리팩토링 및 명령어 최적화](https://cultivo-hy.github.io/docker/image/usage/2019/03/14/Docker정리/#도커-이미지-리팩토링-및-명령어-최적화))

##### 방금 빌드한 이미지를 실행

테스트 삼아 로컬에서 이미지를 실행해보자.

```powershell
D:\docku2\example-docker-nodejs>docker run
"docker run" requires at least 1 argument.
See 'docker run --help'.
Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
Run a command in a new container # 새 컨테이너의 명령(CMD ["node","app.js"])을 실행한다...

D:\docku2\example-docker-nodejs>docker run -d -p 8080:8080 mydockerimage:1.0
```

이제 브라우저에서 확인 가능하다. 성공적으로 도커 컨테이너를 통해 앱을 실행했다.

##### 배포

☞ 위 과정까지는 로컬에 도커 이미지를 준비하고 컨테이너로 실행한 과정에 해당한다.

☞ 이 도커 이미지를 서버에 복사하고 컨테이너로 실행한다면 이는 배포에 해당한다.

도커 허브에서는 깃 허브와 비슷하게 도커 이미지를 push, pull 할 수 있다. private 이미지는 개인의 경우 하나만 가능하다고 하지만, 다행스럽게도 개인이 직접 private registry를 구축하기 위한 registry 도커 이미지를 도커 허브에서 제공하고 있다. private registry 구축에 대한 자세한 것은 [이 글](https://m.blog.naver.com/complusblog/221000797682)을 참고하고, 일단은 도커 허브를 사용해보자.

##### 도커 허브 로그인

일단 최초 1회(아마도) CLI에서 도커 허브에 로그인하는 과정이 필요하다.

```
D:\docku2\example-docker-nodejs>docker login
D:\docku2\example-docker-nodejs>...
```

##### 도커 이미지 푸시

앞에서 만든 도커 이미지를 도커 허브에 푸시하려면 이미지 이름이 다음 형식을 따라야 하는 것 같다.

```powershell
[도커아이디]/문자열:버전
```

앞에서 만든 이미지 이름은 도커아이디를 포함하지 않는다. `docker tag` 명령으로 도커아이디를 붙여준다.

```powershell
D:\docku2\example-docker-nodejs>docker tag mydockerimage:1.0 [도커아이디]/mydockerimage:1.0
```

위 과정이 번거롭다면 처음에 빌드할 때부터 아래와 같이 빌드하면 된다.

```powershell
D:\docku2\example-docker-nodejs>docker build -t [도커아이디]/example-nodejs:1.0 .
```

어쨋든, 도커아이디가 포함된 이미지 이름이 준비되면 이제 도커 이미지를 도커 허브로 푸시한다. 좀 오래 걸린다. 천만 다행으로, 애플리케이션에 수정을 가한 후 버전업하여 빌드한 이미지는 빠르게 푸시한다.

```powershell
D:\docku2\example-docker-nodejs>docker push [도커아이디]/example-nodejs:1.0 # 오래 걸림
D:\docku2\example-docker-nodejs>docker push [도커아이디]/example-nodejs:1.1 # 금방 됨
```

##### 도커 이미지 풀

이제 서버에서 도커 이미지를 풀 할 차례다. putty 등을 사용해 centos에 접속한 다음, 도커를 설치해본다. 귀찮아서 편의 스크립트를 사용. 한......참 기다리면 설치가 끝난다.

```
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

준비가 되었으면 도커 이미지를 풀 해보자. 단, 이 과정은 생략해도 된다. 아래 단계에서 필요하다면 자동으로 `docker pull`을 수행한다. 참고로 centos의 경우 이미지는 /var/lib/docker/overlay2에 저장되는 것 같다.

```powershell
docker pull [도커아이디]/example-nodejs:1.0
```

##### 도커 이미지 실행

도커 이미지를 실행하고 컨테이너(도커 프로세스) 목록을 확인해보자. 애플리케이션이 정상 작동한다.

```powershell
docker run -d -p 8080:8080 [도커아이디]/example-nodejs:1.0
> docker ps
CONTAINER ID   IMAGE                           ...  PORTS                    ...
62240c48653a   [도커아이디]/example-nodejs:1.0        0.0.0.0:8080->8080/tcp
curl localhost:8080/?name=docku # {"msg":"Hello docku!"}
```

##### 정리

여기까지의 과정은 애플리케이션을 도커 이미지로 빌드하고, 푸시하고, (풀해서) 실행하는 구조로 정리할 수 있다.

```powershell
docker build -t [도커아이디]/example-nodejs:1.0 . # Dockerfile, .dockerignore 사용
docker push [도커아이디]/example-nodejs:1.0 # 도커 허브
docker pull [도커아이디]/example-nodejs:1.0 # 생략 가능
docker run -d -p 8080:8080 [도커아이디]/example-nodejs:1.0
```

#### 도커 실습3

다음 글을 참고하였다.

- [DB 유지](https://docs.docker.com/get-started/05_persisting_data/)
- [바인드 마운트 사용](https://docs.docker.com/get-started/06_bind_mounts/)
- [다중 컨테이너 앱](https://docs.docker.com/get-started/07_multi_container/)

##### 컨테이너 2개 준비

```powershell
git clone https://github.com/docker/getting-started
cd getting-started/app
docker build -t getting-started .
docker run -dp 3000:3000 getting-started
docker run -dp 8080:3000 getting-started
# Dockerfile
 FROM node:12-alpine
 RUN apk add --no-cache python g++ make
 WORKDIR /app
 COPY . .
 RUN yarn install --production
 CMD ["node", "src/index.js"]
```

##### 각 컨테이너가 고유의 데이터를 갖고 있는 것을 확인

localhost:3000 에서 todo 추가한 뒤 localhost:8080 를 확인해보면 추가된 todo가 보이지 않는다.

Docker Desktop 컨테이너 CLI 버튼을 눌러 todo.db 의 수정시간을 확인해보면 별개의 파일임을 알 수 있다.

```bash
> ls -l /etc/todos
-rw-r--r--    1 root     root          8192 Apr  2 07:57 todo.db      # 컨테이너1
-rw-r--r--    1 root     root          8192 Apr  2 07:55 todo.db      # 컨테이너2
```

##### 명명된 볼륨을 사용해 데이터를 유지

명명된 볼륨을 생성하고 이를 컨테이너 내의 폴더에 연결해주면 폴더의 파일들이 캡처된다. 볼륨은 호스트 폴더에 위치하지 않고 도커의 관리하에 존재한다고 한다. 볼륨을 사용하면 **컨테이너를 삭제해도 데이터를 유지**할 수 있다. 또, 컨테이너 간 데이터가 공유된다. localhost:3000 에서 추가한 todo가 localhost:8080 에서도 출력되는 것을 확인할 수 있다.

```powershell
docker volume create myvol # 볼륨 생성
docker volume inspect myvol # 볼륨 정보 확인
docker run -dp 3000:3000 -v myvol:/etc/todos getting-started # 명명된 볼륨을 연결한 컨테이너1
docker run -dp 8080:3000 -v myvol:/etc/todos getting-started # 명명된 볼륨을 연결한 컨테이너2
```

##### 바인드 마운트를 사용해 컨테이너 외부의 임의의 폴더를 연결

> 바인드 마운트를 사용하는 것은 로컬 개발 설정에서 매우 일반적입니다. 장점은 **개발 머신에 모든 빌드 도구와 환경을 설치할 필요가 없다는 것**입니다. 단일 `docker run`명령으로 개발 환경을 가져와 사용할 수 있습니다. [출처](https://docs.docker.com/get-started/06_bind_mounts/)

다음 파워쉘 명령은 nodemon을 설치하고 이를 사용한다(전에는 node src/index.js). app.js 소스를 수정한 뒤 브라우저를 새로고침 해보면, 이미지를 다시 빌드하지 않았는데도 수정 사항이 반영되어 있다.

```powershell
docker run -dp 3000:3000 -w /myapp -v "$(pwd):/myapp" node:12-alpine sh -c "yarn install && yarn run dev"
```

위 명령어를 살펴보면, 일단 getting-started 이미지가 아닌 node 이미지를 사용하고 있다. todo 소스가 없는 이미지이다. 그리고 -w 옵션으로 워킹 디렉토리를 지정하고, -v 옵션으로 현재 경로(프로젝트 폴더)를 컨테이너 내의 /myapp에 연결해준다. 명명된 볼륨이 아닌 현재 프로젝트 폴더를 /myapp이라는 이름으로 마운트하는 것이다. 마지막 인자를 통해 yarn install과 yarn run dev을 수행한다. 참고로 -w와 -v 옵션은 아래와 같다.

```powershell
> docker run --help
  -v, --volume list                    Bind mount a volume
      --volume-driver string           Optional volume driver for the container
      --volumes-from list              Mount volumes from the specified container(s)
  -w, --workdir string                 Working directory inside the container
```

도커 컨테이너로 들어가서 살펴보면 복사한 적도 없는데 프로젝트 파일들이 있는 것을 볼 수 있다.

```powershell
> docker exec [컨테이너아이디] ls -l   # Docker Desktop에서 컨테이너 CLI 버튼을 이용해도 된다.
total 180
-rwxrwxrwx    1 root     root           139 Apr  2 06:05 Dockerfile
drwxr-xr-x    1 root     root          4096 Apr  2 08:17 node_modules
-rwxrwxrwx    1 root     root           657 Apr  2 07:46 package.json
drwxrwxrwx    1 root     root          4096 Apr  2 07:46 spec
drwxrwxrwx    1 root     root          4096 Apr  2 07:46 src
-rwxrwxrwx    1 root     root        183766 Apr  2 07:46 yarn.lock
```

이번에는 위와 같은 동작을 하는 이미지를 직접 빌드해서 테스트해보자(파워쉘).

```powershell
# Dockerfile
FROM node:12-alpine
WORKDIR /myapp
COPY package.json .
RUN yarn install
CMD yarn run dev

> docker build -t bind-mount .
> docker run -dp 3000:3000 -v "$(pwd):/myapp" bind-mount
```

이번엔 내 컴퓨터의 nodejs를 제거해보았다. 이제까지의 내용으로 미루어보면 내 컴퓨터에 nodejs는 없어도 될 것이고, 예상했듯이 컨테이너의 nodemon이 바인드 마운트한 소스의 수정사항을 반영했다. 정말로 도커 문서의 표현대로 **개발 머신에 빌드 도구와 환경을 설치할 필요가 없이 개발**이 가능하다. 개발 머신에는 소스만 있으면 되는 것이다...

##### 다중 컨테이너 - 네트워크

같은 "네트워크"에 있는 컨테이너끼리는 통신할 수 있다. 먼저 "네트워크"를 만든다.

```powershell
docker network create todo-app
```

mysql 이미지를 사용하여 컨테이너를 생성하되 네트워크를 지정한다. docker run으로 명명된 볼륨을 사용하면 볼륨이 자동 생성된다.

```powershell
docker run -d --network todo-app --network-alias mysql -v todo-mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=secret -e MYSQL_DATABASE=todos mysql:5.7
```

컨테이너에서 mysql을 실행해본다. mysql이 잘 실행되고 있음을 확인할 수 있다.

```powershell
> docker exec -it <mysql-container-id> mysql -p
Enter password: secret # 비번
Welcome to the MySQL monitor.
...
mysql> show databases; # 조회
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| todos              |
+--------------------+
5 rows in set (0.00 sec)
```

컨테이너끼리의 통신은 **네트워크 별칭**을 사용해 이루어진다. 문서에서 예시로 든 nicolaka/netshoot 이미지에 포함된 dig라는 도구는 인자로 네트워크 별칭을 받아 IP를 출력해준다.

```powershell
> docker run -it --network todo-app nicolaka/netshoot
...
Welcome to Netshoot! (github.com/nicolaka/netshoot)
852d5372317f  ~  dig mysql # 여기서 mysql은 위에서 --network-alias 로 지정해준 네트워크 별칭
...
;; ANSWER SECTION:
mysql.                  600     IN      A       172.19.0.2 # ANSWER SECTION에서 IP 확인
...
```

이제 todo 컨테이너를 생성하는데, 환경변수로 mysql을 설정해준다. 운영에서는 환경변수로 로그인 정보를 전달하면 [안 된다](https://diogomonica.com/2017/03/27/why-you-shouldnt-use-env-variables-for-secret-data/).

```powershell
docker run -dp 3000:3000 -w /app -v ${PWD}:/app --network todo-app -e MYSQL_HOST=mysql -e MYSQL_USER=root -e MYSQL_PASSWORD=secret -e MYSQL_DB=todos node:12-alpine sh -c "yarn install && yarn run dev"
```

컨테이너 로그를 보자.

```powershell
> docker log <app-container-id>
...
[nodemon] starting `node src/index.js`
Waiting for mysql:3306.
Connected!
Connected to mysql db at host mysql # 네트워크 별칭을 사용하여 접속 성공
Listening on port 3000
```

mysql 컨테이너에서 데이터를 확인해보자. 네트워크를 통해 컨테이너간 통신이 이루어진 것을 확인할 수 있다.

```powershell
> docker exec -it <mysql-container-id> mysql -p todos
mysql> select * from todo_items;
+--------------------------------------+------+-----------+
| id                                   | name | completed |
+--------------------------------------+------+-----------+
| e6adf46f-1990-47e5-ae51-8d6afa4e1501 | 1    |         0 |
| b999bb62-9dbb-4c8c-8854-314037dff8c3 | 2    |         0 |
| 6bb20ead-1a7a-433a-920c-08dc3ad53943 | 3    |         0 |
+--------------------------------------+------+-----------+
```

#### Docker Compose - 여러 컨테이너를 한번에 켜고 끄기

docker-compose를 사용하여 여러 컨테이너를 한번에 관리할 수 있다. docker-compose.yaml 파일을 만든다.

```yaml
version: "3.7"

services:
  app:
    image: node:12-alpine
    command: sh -c "yarn install && yarn run dev"
    ports:
      - 3000:3000
    working_dir: /app
    volumes:
      - ./:/app
    environment:
      MYSQL_HOST: mysql
      MYSQL_USER: root
      MYSQL_PASSWORD: secret
      MYSQL_DB: todos

  mysql:
    image: mysql:5.7
    volumes:
      - todo-mysql-data:/var/lib/mysql
    environment: 
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: todos

volumes:
  todo-mysql-data:
```

실행해보자. yaml 파일에서 네트워크를 따로 언급하지 않았는데 자동 생성된다. 서비스 명칭이 네트워크 별칭으로 사용되었다. 볼륨도 생성되었다. 도커 데스크탑에는 compose 라는 항목으로 두 컨테이너가 묶여있다.

```powershell
> docker-compose up -d # 실행
Creating network "compose_default" with the default driver
Creating volume "compose_todo-mysql-data" with default driver
Creating compose_mysql_1 ... done
Creating compose_app_1   ... done
> docker-compose down # 종료
```

#### 캐싱과 다단계 빌드 - 이미지 빌드를 효율적으로 하기 위해...

##### 캐싱

Dockerfile을 아래와 같이 구성하면 캐싱을 활용할 수 있다.

```powershell
# Dockerfile
FROM node:12-alpine
WORKDIR /app
COPY package.json yarn.lock ./
RUN yarn install --production # package.json이 변경되지 않는 한 여기까지는 캐시됨
COPY . .
CMD ["node", "/app/src/index.js"]
```

.dockerignore 파일을 사용하여 이미지 빌드에서 제외할 폴더를 지정할 수도 있다.

##### 다단계 빌드

여태까진 FROM을 하나만 썼는데 꼭 그럴 필요는 없다.

```powershell
# Maven/Tomcat
FROM maven AS build # maven 이미지에서 시작하여 빌드를 마친 후
WORKDIR /app
COPY . .
RUN mvn package

FROM tomcat # tomcat 이미지에 결과물만 복사
COPY --from=build /app/target/file.war /usr/local/tomcat/webapps 
# React
FROM node:12 AS build # node 이미지에서 시작하여 빌드를 마친 후
WORKDIR /app
COPY package* yarn.lock ./
RUN yarn install
COPY public ./public
COPY src ./src
RUN yarn run build

FROM nginx:alpine # nginx 이미지에 결과물만 복사
COPY --from=build /app/build /usr/share/nginx/html
```

#### 도커 이미지 자동 업데이트

watchtower 등을 사용하면 컨테이너를 재생성하지 않아도 된다고 한다.

## 오케스트레이션

#### 오케스트레이션 요약

- 오케스트레이션 : 컨테이너 관리 자동화.
- 필요성 : 마이크로 서비스 프로덕션 환경에서 컨테이너를 수백 개 이상 운용해야 할 때, 수동 관리의 한계
- 기능 : 클라우드와 같은 환경에서 컨테이너를 자동으로 이동하고 확장. 컨테이너 상태 모니터링 및 장애 조치. 오버레이 네트워크 제공. 컨테이너 이동 시에도 지속적인 통신이 가능하도록 검색 제공. 클러스터 및 Docker 호스트 관리 간소화. 기타 등등...
- 대표적인 오케스트레이터 : 도커 스웜, 쿠버네티스, 아파치 메소스, ...

#### 문서 살펴보기 - 오케스트레이션

##### 도커 문서

- [오케스트레이션](https://docs.docker.com/get-started/orchestration/)

> 컨테이너화 된 프로세스의 이식성과 재현성은 **클라우드 및 데이터 센터에서 컨테이너화 된 애플리케이션을 이동하고 확장 할 수있는 기회를 제공**합니다. 컨테이너는 이러한 애플리케이션이 어디서나 동일한 방식으로 실행되도록 효과적으로 보장하므로 이러한 모든 환경을 빠르고 쉽게 활용할 수 있습니다. 또한 응용 프로그램을 확장함에 따라 해당 **응용 프로그램의 유지 관리를 자동화하고 실패한 컨테이너를 자동으로 교체하고 수명주기 동안 해당 컨테이너의 업데이트 및 재구성 롤아웃을 관리**하는 데 도움이되는 몇 가지 도구가 필요합니다.
>
> **컨테이너화 된 애플리케이션을 관리, 확장 및 유지 관리하는 도구**를 *오케 스트레이터* 라고 하며 가장 일반적인 예로 *Kubernetes* 및 *Docker Swarm이* 있습니다. 이 두 오케 스트레이터의 개발 환경 배포는 Docker Desktop에서 제공하며,이 가이드 전체에서 첫 번째 오케스트레이션되고 컨테이너화 된 애플리케이션을 만드는 데 사용할 것입니다. [출처](https://docs.docker.com/get-started/orchestration/)

> Kubernetes는 컨테이너 자체의 기능을 넘어서 **컨테이너화 된 애플리케이션의 확장, 네트워킹, 보안 및 유지 관리를위한 다양한 도구를 제공** [출처](https://docs.docker.com/get-started/kube-deploy/)

##### 마이크로소프트 문서

- [Windows 컨테이너 오케스트레이션 개요](https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/about/overview-container-orchestrators)

> 작은 크기와 애플리케이션 방향으로 인해 컨테이너는 빠른 전달 환경과 마이크로 서비스 기반 아키텍처에 적합합니다. 하지만 컨테이너와 마이크로 서비스를 사용하는 환경에는 추적해야 하는 구성 요소가 수백 또는 수천 개 있을 수 있습니다. 수십 개의 가상 머신이나 실제 서버는 수동으로 관리할 수 있지만, 프로덕션 규모의 컨테이너 환경은 자동화 없이 제대로 관리할 수 있는 방법이 없습니다. 이런 작업은 Orchestrator에게 맡겨야 합니다. Orchestrator는 **다수의 컨테이너 및 이들이 서로 상호 작용하는 방식을 자동화하고 관리**하는 프로세스입니다.
>
> Orchestrator는 다음 작업을 수행합니다.
>
> - 일정 예약: 컨테이너 이미지와 리소스 요청이 지정되면, Orchestrator는 컨테이너를 실행하기에 적합한 머신을 찾습니다.
> - 선호도/선호도 방지: 컨테이너 세트가 성능을 위해 서로 가까이 있어야 하는지 또는 가용성을 위해 멀리 떨어져 있어야 하는지를 지정합니다.
> - 상태 모니터링: 컨테이너 오류를 감시하고 자동으로 일정을 조정합니다.
> - 장애 조치(failover): 각 머신에서 실행되는 항목을 계속 추적하고 오류가 발생한 머신에서 정상 노드로 컨테이너 일정을 조정합니다.
> - 크기 조정: 필요에 맞게 수동 또는 자동으로 컨테이너 인스턴스를 추가 또는 제거합니다.
> - 네트워킹: 여러 호스트 머신과 통신할 수 있도록 컨테이너를 조정하는 오버레이 네트워크를 제공합니다.
> - 서비스 검색: 컨테이너가 호스트 머신 간에 이동하고 IP 주소를 변경하더라도 컨테이너가 자동으로 서로를 찾을 수 있습니다.
> - 조정된 애플리케이션 업그레이드: 애플리케이션 중단 시간을 방지하고 문제가 발생하는 경우 롤백이 가능하도록 컨테이너 업그레이드를 관리합니다. [출처](https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/about/overview-container-orchestrators)

##### 레드햇 문서

- [컨테이너 오케스트레이션이란 무엇인가?](https://www.redhat.com/ko/topics/containers/what-is-container-orchestration)

> 쿠버네티스와 같은 컨테이너 오케스트레이션 툴을 사용할 때는 YAML 또는 JSON 파일을 사용해 애플리케이션 설정에 대해 설명하게 됩니다. 설정 파일은 설정 관리 툴에 컨테이너 이미지의 위치와 네트워크를 구축하는 방법, 로그를 저장할 장소를 알려줍니다.
>
> 새 컨테이너를 배포할 때 컨테이너 관리 도구는 정의된 요구 사항 또는 제한 사항을 고려하여 배포를 클러스터에 자동으로 예약하고 올바른 호스트를 찾습니다. 그러면 오케스트레이션 툴이 작성 파일에 정의된 사양에 따라 컨테이너의 라이프사이클을 관리합니다. [출처](https://www.redhat.com/ko/topics/containers/what-is-container-orchestration)

##### 쿠버네티스 문서

- [쿠버네티스란 무엇인가?](https://kubernetes.io/ko/docs/concepts/overview/what-is-kubernetes/)

> 컨테이너는 애플리케이션을 포장하고 실행하는 좋은 방법이다. 프로덕션 환경에서는 애플리케이션을 실행하는 컨테이너를 관리하고 가동 중지 시간이 없는지 확인해야 한다. 예를 들어 컨테이너가 다운되면 다른 컨테이너를 다시 시작해야 한다. 이 문제를 시스템에 의해 처리한다면 더 쉽지 않을까?
>
> 그것이 쿠버네티스가 필요한 이유이다! 쿠버네티스는 분산 시스템을 탄력적으로 실행하기 위한 프레임 워크를 제공한다. **애플리케이션의 확장과 장애 조치를 처리하고, 배포 패턴 등을 제공**한다. 예를 들어, 쿠버네티스는 시스템의 카나리아 배포를 쉽게 관리 할 수 있다.
>
> 쿠버네티스는 다음을 제공한다.
>
> - **서비스 디스커버리와 로드 밸런싱** 쿠버네티스는 DNS 이름을 사용하거나 자체 IP 주소를 사용하여 컨테이너를 노출할 수 있다. 컨테이너에 대한 트래픽이 많으면, 쿠버네티스는 네트워크 트래픽을 로드밸런싱하고 배포하여 배포가 안정적으로 이루어질 수 있다.
> - **스토리지 오케스트레이션** 쿠버네티스를 사용하면 로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탑재 할 수 있다.
> - **자동화된 롤아웃과 롤백** 쿠버네티스를 사용하여 배포된 컨테이너의 원하는 상태를 서술할 수 있으며 현재 상태를 원하는 상태로 설정한 속도에 따라 변경할 수 있다. 예를 들어 쿠버네티스를 자동화해서 배포용 새 컨테이너를 만들고, 기존 컨테이너를 제거하고, 모든 리소스를 새 컨테이너에 적용할 수 있다.
> - **자동화된 빈 패킹(bin packing)** 컨테이너화된 작업을 실행하는데 사용할 수 있는 쿠버네티스 클러스터 노드를 제공한다. 각 컨테이너가 필요로 하는 CPU와 메모리(RAM)를 쿠버네티스에게 지시한다. 쿠버네티스는 컨테이너를 노드에 맞추어서 리소스를 가장 잘 사용할 수 있도록 해준다.
> - **자동화된 복구(self-healing)** 쿠버네티스는 실패한 컨테이너를 다시 시작하고, 컨테이너를 교체하며, '사용자 정의 상태 검사'에 응답하지 않는 컨테이너를 죽이고, 서비스 준비가 끝날 때까지 그러한 과정을 클라이언트에 보여주지 않는다.
> - **시크릿과 구성 관리** 쿠버네티스를 사용하면 암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리 할 수 있다. 컨테이너 이미지를 재구성하지 않고 스택 구성에 시크릿을 노출하지 않고도 시크릿 및 애플리케이션 구성을 배포 및 업데이트 할 수 있다. [출처](https://kubernetes.io/ko/docs/concepts/overview/what-is-kubernetes/)

##### 기타 문서

- [Docker - Get started - Orchestration](https://docs.docker.com/get-started/orchestration/)
- [[Infra\] Docker Swarm이란?](https://chrisjune-13837.medium.com/infra-docker-swarm이란-595d33160379)
- [[Infra\] Kubernetes vs Swarm vs Mesos 비교](https://chrisjune-13837.medium.com/infra-kubernetes-vs-swarm-vs-mesos-비교-b04b2cd032ab)

#### 문서 살펴보기 - 쿠버네티스

##### 레드햇 문서

- [쿠버네티스](https://www.redhat.com/ko/topics/containers/what-is-kubernetes)
- [오픈시프트](https://www.redhat.com/ko/technologies/cloud-computing/openshift/get-started?intcmp=701f20000012m1vAAA#buy)

> **마스터:** 쿠버네티스 노드를 제어하는 머신입니다. 여기에서 모든 태스크 할당이 시작됩니다.
>
> **노드:** 할당된 태스크를 요청대로 수행하는 시스템입니다. 쿠버네티스 마스터가 이러한 노드를 제어합니다.
>
> **포드:** 단일 노드에 배포된 하나 이상의 컨테이너 그룹입니다. 포드에 있는 모든 컨테이너는 IP 주소, IPC, 호스트 이름, 기타 리소스를 공유하며 포드는 기본 컨테이너에서 네트워크와 스토리지를 추상화합니다 이렇게 하면 클러스터에서 컨테이너를 더 쉽게 이동할 수 있습니다.
>
> **복제 컨트롤러:** 이 컨트롤러는 클러스터에서 실행되어야 하는 동일한 포드 사본의 개수를 제어합니다.
>
> **서비스:** 포드에서 작업 정의를 분리합니다 쿠버네티스 서비스 프록시는 클러스터에서 다른 위치로 이동한 경우든 교체된 경우든 서비스 요청을 적절한 포드로 자동 수신합니다.
>
> **Kubelet:** 이 서비스는 노드에서 실행되며 컨테이너 매니페스트를 읽고, 정의된 컨테이너가 시작되어 실행 중인지 확인합니다.
>
> **kubectl:** 쿠버네티스의 명령줄 설정 툴입니다. [출처](https://www.redhat.com/ko/topics/containers/what-is-kubernetes)

##### 쿠버네티스 문서

- 용어
  - **클러스터** : 컨테이너화된 애플리케이션을 실행하는 노드라고 하는 워커 머신의 집합. 모든 클러스터는 최소 한 개의 워커 노드를 가진다.
  - **노드** : 쿠버네티스의 워커 머신이다.
  - **컨테이너** : 소프트웨어와 그것에 종속된 모든 것을 포함한 가볍고 휴대성이 높은 실행 가능 이미지.
  - **파드** : 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.
  - **워크로드** : 클러스터의 컨테이너를 동작시키고 관리하기 위해 사용하는 오브젝트이다.
  - **디플로이먼트** : 클러스터에서 복제된 애플리케이션을 관리한다.
  - **레플리카셋** : 지정된 수의 파드 레플리카가 동시에 실행이 되도록 보장한다.
  - **스테이트풀셋** : 내구성이 있는 스토리지와 파드별로 지속성 식별자를 사용해서 파드 집합의 디플로이먼트와 스케일링을 관리한다.
  - **데몬셋** : 파드의 복제본을 클러스터 노드 집합에서 동작하게 한다.
  - **잡** : 완료를 목표로 실행되는 유한 또는 배치 작업.
  - **컨트롤러** : API 서버를 통해 클러스터의 공유된 상태를 감시하고, 현재 상태를 원하는 상태로 이행시키는 컨트롤 루프.
  - **컨트롤 플레인** : 컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어.
  - **서비스** : 네트워크 서비스로 파드 집합에서 실행 중인 애플리케이션을 노출하는 방법.
  - **볼륨** : 데이터를 포함하고 있는 디렉터리이며, 파드의 컨테이너에서 접근 가능하다.
  - 컨테이너 런타임 : 컨테이너 실행을 담당하는 소프트웨어이다.
  - **kubelet** : 클러스터의 각 노드에서 실행되는 에이전트. kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.
  - **kube-proxy** : 클러스터의 각 노드에서 실행되는 네트워크 프록시이다.
- 클러스터, 노드, 파드에 대한 개념도 - [이미지 출처](https://kubernetes.io/ko/docs/tutorials)

![img](https://d33wubrfki0l68.cloudfront.net/8700a7f5f0008913aa6c25a1b26c08461e4947c7/cfc2c/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg)

![img](https://d33wubrfki0l68.cloudfront.net/5cb72d407cbe2755e581b6de757e0d81760d5b86/a9df9/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg)

![img](https://d33wubrfki0l68.cloudfront.net/fe03f68d8ede9815184852ca2a4fd30325e5d15a/98064/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg)

- [클러스터](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/)

> 쿠버네티스는 **컴퓨터들을 연결하여 단일 형상으로 동작하도록 컴퓨팅 클러스터를 구성**하고 높은 가용성을 제공하도록 조율한다. 사용자는 쿠버네티스의 **추상화 개념을 통해 개별 머신에 얽매이지 않고 컨테이너화된 애플리케이션을 클러스터에 배포**할 수 있다. 이렇게 새로운 배포 모델을 활용하려면, 애플리케이션을 개별 호스트에 독립적인 방식으로 패키징할 필요가 있다. 즉, 컨테이너화가 필요하다. 예전 배치 모델인 설치형 애플리케이션이 특정 머신의 호스트와 밀접하게 통합되는 패키지인 것에 비해, 컨테이너화된 애플리케이션은 유연성(flexible)과 가용성(available)이 훨씬 높다.
>
> 쿠버네티스 클러스터는 두 가지 형태의 자원으로 구성된다.
>
> - **컨트롤 플레인**은 클러스터를 조율한다.
> - **노드**는 애플리케이션을 구동하는 작업자(worker)이다.
>
> 쿠버네티스 클러스터는 물리 및 가상 머신 모두에 설치될 수 있다.

- [컨트롤 플레인](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/)

> 컨트롤 플레인은 클러스터 관리를 담당한다. 컨트롤 플레인은 애플리케이션을 스케줄링하거나, 애플리케이션의 항상성을 유지하거나, 애플리케이션을 스케일링하고, 새로운 변경사항을 순서대로 반영(rolling out)하는 일과 같은 클러스터 내 모든 활동을 조율한다.
>
> 애플리케이션을 쿠버네티스에 배포하기 위해서는, 컨트롤 플레인에 애플리케이션 컨테이너의 구동을 지시하면 된다. 그러면 컨트롤 플레인은 컨테이너를 클러스터의 어느 노드에 구동시킬지 스케줄한다. 노드는 컨트롤 플레인이 제공하는 쿠버네티스 API를 통해서 컨트롤 플레인과 통신한다. 최종 사용자도 쿠버네티스 API를 사용해서 클러스터와 직접 상호작용(interact)할 수 있다.

- [노드](https://kubernetes.io/ko/docs/concepts/architecture/nodes/)

> 쿠버네티스는 컨테이너를 파드내에 배치하고 노드에서 실행함으로 워크로드를 구동한다. 노드는 클러스터에 따라 **가상 또는 물리적 머신**일 수 있다. 각 노드는 **컨트롤 플레인에 의해 관리되며 파드를 실행하는 데 필요한 서비스를 포함**한다.
>
> **일반적으로 클러스터에는 여러 개의 노드가 있으며, 학습 또는 리소스가 제한되는 환경에서는 하나만 있을 수도 있다.**
>
> 노드의 컴포넌트에는 kubelet, 컨테이너 런타임 그리고 kube-proxy가 포함된다.

- [워크로드](https://kubernetes.io/ko/docs/concepts/workloads/)

> 워크로드는 **쿠버네티스에서 구동되는 애플리케이션**이다. 워크로드가 단일 컴포넌트이거나 함께 작동하는 여러 컴포넌트이든 관계없이, 쿠버네티스에서는 워크로드를 **일련의 파드 집합 내에서 실행**한다. 쿠버네티스에서 Pod 는 클러스터에서 실행 중인 컨테이너 집합을 나타낸다.

- [파드](https://kubernetes.io/ko/docs/concepts/workloads/pods/)

> *파드(Pod)* 는 **쿠버네티스에서 생성하고 관리할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위**이다.
>
> 파드 (고래 떼(pod of whales)나 콩꼬투리(pea pod)와 마찬가지로)는 하나 이상의 **컨테이너의 그룹**이다. 이 그룹은 **스토리지 및 네트워크를 공유**하고, 해당 컨테이너를 구동하는 방식에 대한 명세를 갖는다. 파드의 콘텐츠는 항상 함께 배치되고, 함께 스케줄되며, 공유 콘텍스트에서 실행된다. 파드는 **애플리케이션 별 "논리 호스트"를 모델링**한다. 여기에는 상대적으로 밀접하게 결합된 하나 이상의 애플리케이션 컨테이너가 포함된다. **클라우드가 아닌 콘텍스트에서, 동일한 물리 또는 가상 머신에서 실행되는 애플리케이션은 동일한 논리 호스트에서 실행되는 클라우드 애플리케이션과 비슷**하다.

> 파드의 공유 콘텍스트는 리눅스 네임스페이스, 컨트롤 그룹(cgroup) 및 도커 컨테이너를 격리하는 것과 같이 잠재적으로 다른 격리 요소들이다. 파드의 콘텍스트 내에서 개별 애플리케이션은 추가적으로 하위 격리가 적용된다.
>
> 도커 개념 측면에서, 파드는 **공유 네임스페이스와 공유 파일시스템 볼륨이 있는 도커 컨테이너 그룹**과 비슷하다.

> 일반적으로 싱글톤(singleton) 파드를 포함하여 **파드를 직접 만들 필요가 없다**. 대신, **디플로이먼트(Deployment) 또는 잡(Job)과 같은 워크로드 리소스를 사용하여 생성**한다. 파드가 **상태를 추적해야 한다면, 스테이트풀셋(StatefulSet) 리소스를 고려**한다.

- [디플로이먼트](https://kubernetes.io/ko/docs/concepts/workloads/controllers/deployment/)

> 디플로이먼트(Deployment) 는 **파드와 레플리카셋(ReplicaSet)에 대한 선언적 업데이트를 제공**한다.
>
> 디플로이먼트에서 **의도하는 상태를 설명**하고, 디플로이먼트 컨트롤러(Controller)는 현재 상태에서 의도하는 상태로 비율을 조정하며 변경한다. 새 레플리카셋을 생성하는 디플로이먼트를 정의하거나 기존 디플로이먼트를 제거하고, 모든 리소스를 새 디플로이먼트에 적용할 수 있다.

- [레플리카셋](https://kubernetes.io/ko/docs/concepts/workloads/controllers/replicaset/)

> 레플리카셋의 목적은 **레플리카 파드 집합의 실행을 항상 안정적으로 유지**하는 것이다. 이처럼 레플리카셋은 보통 **명시된 동일 파드 개수에 대한 가용성을 보증**하는데 사용한다.

> 레플리카셋을 정의하는 필드는 획득 가능한 파드를 식별하는 방법이 명시된 셀렉터, 유지해야 하는 파드 개수를 명시하는 레플리카의 개수, 그리고 레플리카 수 유지를 위해 생성하는 신규 파드에 대한 데이터를 명시하는 파드 템플릿을 포함한다. 그러면 레플리카셋은 필드에 지정된 **설정을 충족하기 위해 필요한 만큼 파드를 만들고 삭제**한다. 레플리카셋이 새로운 파드를 생성해야 할 경우, 명시된 파드 템플릿을 사용한다.

> 레플리카셋은 지정된 수의 파드 레플리카가 항상 실행되도록 보장한다. 그러나 디플로이먼트는 레플리카셋을 관리하고 다른 유용한 기능과 함께 파드에 대한 선언적 업데이트를 제공하는 상위 개념이다. 따라서 우리는 사용자 지정 오케스트레이션이 필요하거나 업데이트가 전혀 필요하지 않은 경우라면 **레플리카셋을 직접적으로 사용하기 보다는 디플로이먼트를 사용하는 것을 권장**한다.
>
> 이는 **레플리카셋 오브젝트를 직접 조작할 필요가 없다**는 것을 의미한다. 대신 디플로이먼트를 이용하고 사양 부분에서 애플리케이션을 정의하면 된다.

- [잡](https://kubernetes.io/ko/docs/concepts/workloads/controllers/job/) - (일종의 배치작업 성격을 지님. 종료될 것으로 예상되는 파드를 관리)

> 잡에서 하나 이상의 파드를 생성하고 지정된 수의 파드가 성공적으로 종료될 때까지 계속해서 파드의 실행을 재시도한다. 파드가 성공적으로 완료되면, 성공적으로 완료된 잡을 추적한다. 지정된 수의 성공 완료에 도달하면, 작업(즉, 잡)이 완료된다. 잡을 삭제하면 잡이 생성한 파드가 정리된다.
>
> 간단한 사례는 잡 오브젝트를 하나 생성해서 파드 하나를 안정적으로 실행하고 완료하는 것이다. 첫 번째 파드가 실패 또는 삭제된 경우(예로는 노드 하드웨어의 실패 또는 노드 재부팅) 잡 오브젝트는 새로운 파드를 기동시킨다.
>
> 잡을 사용하면 여러 파드를 병렬로 실행할 수도 있다.

> 구성 등의 논리적 오류로 인해 약간의 재시도 이후에 잡을 실패하게 만들려는 경우가 있다. 이렇게 하려면 .spec.backoffLimit 에 잡을 실패로 간주하기 이전에 재시도할 횟수를 설정한다.

- [크론잡](https://kubernetes.io/ko/docs/concepts/workloads/controllers/cron-jobs/)

> 크론잡은 백업 실행 또는 이메일 전송과 같은 정기적이고 반복적인 작업을 만드는데 유용하다. 또한 크론잡은 클러스터가 유휴 상태일 때 잡을 스케줄링하는 것과 같이 특정 시간 동안의 개별 작업을 스케줄할 수 있다.

- [스테이트풀셋](https://kubernetes.io/ko/docs/concepts/workloads/controllers/statefulset/)

> 스테이트풀셋은 애플리케이션의 스테이트풀을 관리하는데 사용하는 워크로드 API 오브젝트이다.
>
> 파드 집합의 디플로이먼트와 스케일링을 관리하며, **파드들의 순서 및 고유성을 보장**한다 .
>
> 디플로이먼트와 유사하게, 스테이트풀셋은 동일한 컨테이너 스펙을 기반으로 둔 파드들을 관리한다. 디플로이먼트와는 다르게, 스테이트풀셋은 **각 파드의 독자성을 유지**한다. 이 파드들은 동일한 스팩으로 생성되었지만, 서로 교체는 불가능하다. 다시 말해, 각각은 재스케줄링 간에도 지속적으로 유지되는 식별자를 가진다.
>
> 스토리지 볼륨을 사용해서 워크로드에 지속성을 제공하려는 경우, 솔루션의 일부로 스테이트풀셋을 사용할 수 있다.

- [데몬셋](https://kubernetes.io/ko/docs/concepts/workloads/controllers/daemonset/)

> 데몬셋은 **모든(또는 일부) 노드가 파드의 사본을 실행**하도록 한다. 노드가 클러스터에 추가되면 파드도 추가된다. 노드가 클러스터에서 제거되면 해당 파드는 가비지(garbage)로 수집된다. 데몬셋을 삭제하면 데몬셋이 생성한 파드들이 정리된다.
>
> 데몬셋의 일부 대표적인 용도는 다음과 같다.
>
> - 모든 노드에서 클러스터 스토리지 데몬 실행
> - 모든 노드에서 로그 수집 데몬 실행
> - 모든 노드에서 노드 모니터링 데몬 실행

- [컨트롤러](https://kubernetes.io/ko/docs/concepts/architecture/controller/)

> 로보틱스와 자동화에서 컨트롤 루프 는 시스템 상태를 조절하는 **종료되지 않는 루프**이다.
>
> 쿠버네티스에서 컨트롤러는 **클러스터의 상태를 관찰한 다음, 필요한 경우에 생성 또는 변경을 요청하는 컨트롤 루프**이다. 각 컨트롤러는 현재 **클러스터 상태를 의도한 상태에 가깝게** 이동한다.

> 컨트롤러는 **적어도 하나 이상의 쿠버네티스 리소스 유형을 추적**한다. 이 오브젝트는 의도한 상태를 표현하는 사양 필드를 가지고 있다. **해당 리소스의 컨트롤러(들)은 현재 상태를 의도한 상태에 가깝게 만드는 역**할을 한다.

> **API 서버를 통한 제어**
>
> 잡(Job) 컨트롤러는 쿠버네티스 내장 컨트롤러의 예시이다. 내장 컨트롤러는 **클러스터 API 서버와 상호 작용하며 상태를 관리**한다.
>
> 잡은 단일 파드 또는 여러 파드를 실행하고, 작업을 수행한 다음 중지하는 쿠버네티스 리소스이다.
>
> 잡 컨트롤러가 새로운 작업을 확인하면, 클러스터 어딘가에서 노드 집합의 kubelet이 작업을 수행하기에 적합한 수의 파드를 실행하게 한다. **잡 컨트롤러는 어떤 파드 또는 컨테이너를 스스로 실행하지 않는다**. 대신, **잡 컨트롤러는 API 서버에 파드를 생성하거나 삭제하도록 지시**한다. 컨트롤 플레인의 다른 컴포넌트는 신규 정보 (예약 및 실행해야 하는 새 파드가 있다는 정보)에 대응하여, 결국 해당 작업을 완료시킨다.

> **직접 제어**
>
> 잡과는 대조적으로, 일부 컨트롤러는 **클러스터 외부의 것을 변경**해야 할 필요가 있다.
>
> 예를 들어, 만약 컨트롤 루프를 사용해서 클러스터에 충분한 노드들이 있도록 만드는 경우, 해당 컨트롤러는 필요할 때 새 노드를 설정할 수 있도록 현재 클러스터 외부의 무언가를 필요로 한다.
>
> 외부 상태와 상호 작용하는 컨트롤러는 API 서버에서 의도한 상태를 찾은 다음, **외부 시스템과 직접 통신**해서 현재 상태를 보다 가깝게 만든다.

> **컨트롤러를 실행하는 방법**
>
> 쿠버네티스에는 **kube-controller-manager 내부에서 실행되는 내장된 컨트롤러 집합**이 있다. 이 내장 컨트롤러는 중요한 핵심 동작을 제공한다.
>
> 컨트롤 플레인의 **외부에서 실행하는 컨트롤러를 찾아서 쿠버네티스를 확장**할 수 있다. 또는, 원하는 경우 **새 컨트롤러를 직접 작성**할 수 있다.

- [컨테이너 환경 변수](https://kubernetes.io/ko/docs/concepts/containers/container-environment/)

> 쿠버네티스 컨테이너 환경은 컨테이너에 몇 가지 중요한 리소스를 제공한다.
>
> **컨테이너 정보**
>
> **컨테이너의 호스트네임은 컨테이너가 동작 중인 파드의 이름**과 같다.
>
> Docker 이미지에 정적으로 명시된 환경 변수와 마찬가지로, **파드 정의에서의 사용자 정의 환경 변수**도 컨테이너가 사용할 수 있다.
>
> **클러스터 정보**
>
> **컨테이너가 생성될 때 실행 중이던 모든 서비스의 목록**은 환경 변수로 해당 컨테이너에서 사용할 수 있다. 이 목록은 새로운 컨테이너의 파드 및 쿠버네티스 컨트롤 플레인 서비스와 동일한 네임스페이스 내에 있는 서비스로 한정된다.

- [쿠버네티스 오브젝트](https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/kubernetes-objects/)

> 쿠버네티스 오브젝트 는 쿠버네티스 시스템에서 영속성을 가지는 오브젝트이다. 쿠버네티스는 **클러스터의 상태를 나타내기 위해 이 오브젝트를 이용**한다. 구체적으로 말하자면, 다음같이 기술할 수 있다.
>
> - **어떤 컨테이너화된 애플리케이션이 동작 중인지** (그리고 어느 노드에서 동작 중인지)
> - **그 애플리케이션이 이용할 수 있는 리소스**
> - **그 애플리케이션이 어떻게 재구동 정책, 업그레이드, 그리고 내고장성과 같은 것에 동작해야 하는지에 대한 정책**
>
> 쿠버네티스 오브젝트는 하나의 "의도를 담은 레코드"이다. **오브젝트를 생성하게 되면, 쿠버네티스 시스템은 그 오브젝트 생성을 보장하기 위해 지속적으로 작동**할 것이다. **오브젝트를 생성함으로써, 여러분이 클러스터의 워크로드를 어떤 형태로 보이고자 하는지에 대해 효과적으로 쿠버네티스 시스템에 전한다**. 이것이 바로 여러분의 **클러스터에 대해 의도한 상태**가 된다.
>
> 생성이든, 수정이든, 또는 삭제든 **쿠버네티스 오브젝트를 동작시키려면, 쿠버네티스 API를 이용**해야 한다. 예를 들어, **kubectl** 커맨드-라인 인터페이스를 이용할 때, CLI는 여러분 대신 필요한 쿠버네티스 API를 호출해 준다.

> `spec`을 가진 오브젝트는 오브젝트를 생성할 때 리소스에 원하는 특징(의도한 상태)에 대한 설명을 제공해서 설정한다.
>
> `status` 는 쿠버네티스 시스템과 컴포넌트에 의해 제공되고 업데이트된 오브젝트의 현재 상태를 설명한다.
>
> **예를 들어, 쿠버네티스 디플로이먼트는 클러스터에서 동작하는 애플리케이션을 표현해줄 수 있는 오브젝트이다. 디플로이먼트를 생성할 때, 디플로이먼트 spec에 3개의 애플리케이션 레플리카가 동작되도록 설정할 수 있다. 쿠버네티스 시스템은 그 디플로이먼트 spec을 읽어 spec에 일치되도록 상태를 업데이트하여 3개의 의도한 애플리케이션 인스턴스를 구동시킨다. 만약, 그 인스턴스들 중 어느 하나가 어떤 문제로 인해 멈춘다면(상태 변화 발생), 쿠버네티스 시스템은 보정(이 경우에는 대체 인스턴스를 시작하여)을 통해 spec과 status간의 차이에 대응한다.**

> 쿠버네티스에서 오브젝트를 생성할 때, (이름과 같은)오브젝트에 대한 기본적인 정보와 더불어, 의도한 상태를 기술한 오브젝트 spec을 제시해 줘야만 한다. 오브젝트를 생성하기 위해(직접이든 또는 kubectl을 통해서든) 쿠버네티스 API를 이용할 때, API 요청은 요청 내용 안에 JSON 형식으로 정보를 포함시켜 줘야만 한다. **대부분의 경우 정보를 `.yaml` 파일로 `kubectl`에 제공**한다. kubectl은 API 요청이 이루어질 때, JSON 형식으로 정보를 변환시켜 준다.
>
> 여기 쿠버네티스 디플로이먼트를 위한 필수 필드와 오브젝트 spec을 보여주는 `.yaml` 파일 예시가 있다.
>
> ```yaml
> apiVersion: apps/v1
> kind: Deployment
> metadata:
>   name: nginx-deployment
> spec:
>   selector:
>     matchLabels:
>       app: nginx
>   replicas: 2 # tells deployment to run 2 pods matching the template
>   template:
>     metadata:
>       labels:
>         app: nginx
>     spec:
>       containers:
>       - name: nginx
>         image: nginx:1.14.2
>         ports:
>         - containerPort: 80
> ```

- [쿠버네티스 컴포넌트](https://kubernetes.io/ko/docs/concepts/overview/components/) (도커 데스크탑에서 쿠버네티스를 활성화하면, 해당 이미지들이 IN USE 표시된다)

> **컨트롤 플레인 컴포넌트는 클러스터에 관한 전반적인 결정(예를 들어, 스케줄링)을 수행하고 클러스터 이벤트(예를 들어, 디플로이먼트의 `replicas` 필드에 대한 요구 조건이 충족되지 않을 경우 새로운 파드를 구동시키는 것)를 감지하고 반응한다.**
>
> **kube-apiserver** API 서버는 쿠버네티스 API를 노출하는 쿠버네티스 컨트롤 플레인 컴포넌트이다. API 서버는 쿠버네티스 컨트롤 플레인의 프론트 엔드이다.
>
> **etcd** 모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성·고가용성 키-값 저장소.
>
> **kube-scheduler** 노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트.
>
> **kube-controller-manager** 컨트롤러를 구동하는 마스터 상의 컴포넌트.
>
> 노드 컨트롤러 : 노드가 다운되었을 때 통지와 대응에 관한 책임을 가진다. 레플리케이션 컨트롤러 : 시스템의 모든 레플리케이션 컨트롤러 오브젝트에 대해 알맞은 수의 파드들을 유지시켜 주는 책임을 가진다. 엔드포인트 컨트롤러 : 엔드포인트 오브젝트를 채운다(즉, 서비스와 파드를 연결시킨다.) 서비스 어카운트 & 토큰 컨트롤러 : 새로운 네임스페이스에 대한 기본 계정과 API 접근 토큰을 생성한다.
>
> **cloud-controller-manager** 클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트이다. 클라우드 컨트롤러 매니저를 통해 클러스터를 클라우드 공급자의 API에 연결하고, 해당 클라우드 플랫폼과 상호 작용하는 컴포넌트와 클러스터와 상호 작용하는 컴포넌트를 분리할 수 있다.
>
> 노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것 라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것 서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것

> **노드 컴포넌트는 동작 중인 파드를 유지시키고 쿠버네티스 런타임 환경을 제공하며, 모든 노드 상에서 동작한다.**
>
> **kubelet** 클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.
>
> **kube-proxy** kube-proxy는 클러스터의 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스의 서비스 개념의 구현부이다.
>
> **컨테이너 런타임** 컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다.

> **애드온은 쿠버네티스 리소스(데몬셋, 디플로이먼트 등)를 이용하여 클러스터 기능을 구현한다.**
>
> **DNS**
>
> 클러스터 DNS는 구성환경 내 다른 DNS 서버와 더불어, 쿠버네티스 서비스를 위해 DNS 레코드를 제공해주는 DNS 서버다.
>
> **웹 UI (대시보드)** 대시보드는 쿠버네티스 클러스터를 위한 범용의 웹 기반 UI다. 사용자가 클러스터 자체뿐만 아니라, 클러스터에서 동작하는 애플리케이션에 대한 관리와 문제 해결을 할 수 있도록 해준다.
>
> **컨테이너 리소스 모니터링** 컨테이너 리소스 모니터링은 중앙 데이터베이스 내의 컨테이너들에 대한 포괄적인 시계열 매트릭스를 기록하고 그 데이터를 열람하기 위한 UI를 제공해 준다.
>
> **클러스터-레벨 로깅** 클러스터-레벨 로깅 메커니즘은 검색/열람 인터페이스와 함께 중앙 로그 저장소에 컨테이너 로그를 저장하는 책임을 진다.

- [서비스, 로드밸런싱, 네트워킹](https://kubernetes.io/ko/docs/concepts/services-networking/)

> 쿠버네티스 네트워킹은 다음의 네 가지 문제를 해결한다.
>
> - **파드 내**의 컨테이너는 루프백(loopback)을 통한 네트워킹을 사용하여 통신한다.
> - 클러스터 네트워킹은 **서로 다른 파드 간**의 통신을 제공한다.
> - 서비스 리소스를 사용하면 파드에서 실행 중인 애플리케이션을 **클러스터 외부**에서 접근할 수 있다.
> - 또한 서비스를 사용하여 **클러스터 내부**에서 사용할 수 있는 서비스만 게시할 수 있다.

- [볼륨](https://kubernetes.io/ko/docs/concepts/storage/volumes/)

> 컨테이너 내의 디스크에 있는 파일은 임시적이며, 컨테이너에서 실행될 때 애플리케이션에 적지 않은 몇 가지 문제가 발생한다. 한 가지 문제는 컨테이너가 크래시될 때 파일이 손실된다는 것이다. kubelet은 컨테이너를 다시 시작하지만 초기화된 상태이다. 두 번째 문제는 Pod에서 같이 실행되는 컨테이너간에 파일을 공유할 때 발생한다. 쿠버네티스 볼륨 추상화는 이러한 문제를 모두 해결한다.

> **쿠버네티스는 다양한 유형의 볼륨을 지원**한다. 파드는 여러 볼륨 유형을 동시에 사용할 수 있다. 임시 볼륨 유형은 파드의 수명을 갖지만, 퍼시스턴트 볼륨은 파드의 수명을 넘어 존재한다. 결과적으로, **볼륨은 파드 내에서 실행되는 모든 컨테이너보다 오래 지속되며, 컨테이너를 다시 시작해도 데이터가 보존**된다. **파드가 더 이상 존재하지 않으면, 쿠버네티스는 임시(ephemeral) 볼륨을 삭제하지만, 퍼시스턴트(persistent) 볼륨은 삭제하지 않는다**.
>
> 기본적으로 **볼륨은 디렉터리일 뿐**이며, 일부 데이터가 있을 수 있으며, 파드 내 컨테이너에서 접근할 수 있다. 디렉터리의 생성 방식, 이를 지원하는 매체와 내용은 사용된 특정 볼륨의 유형에 따라 결정된다.

- [쿠버네티스 API](https://kubernetes.io/ko/docs/concepts/overview/kubernetes-api/)

> 쿠버네티스 **컨트롤 플레인의 핵심**은 API 서버이다. **API 서버는 최종 사용자, 클러스터의 다른 부분 그리고 외부 컴포넌트가 서로 통신할 수 있도록 HTTP API를 제공**한다.
>
> 쿠버네티스 API를 사용하면 **쿠버네티스의 API 오브젝트(예: 파드(Pod), 네임스페이스(Namespace), 컨피그맵(ConfigMap) 그리고 이벤트(Event))를 질의(query)하고 조작**할 수 있다.
>
> 대부분의 작업은 **kubectl 커맨드 라인 인터페이스 또는 API를 사용하는 kubeadm과 같은 다른 커맨드 라인 도구를 통해 수행**할 수 있다. 그러나, REST 호출을 사용하여 API에 직접 접근할 수도 있다.

> 쿠버네티스는 주로 **클러스터 내부 통신을 위해 대안적인 Protobuf에 기반한 직렬화 형식을 구현**한다.

> 쿠버네티스는 **오브젝트의 직렬화된 상태를 etcd에 기록**하여 저장한다.

> 필드를 쉽게 제거하거나 리소스 표현을 재구성하기 위해, 쿠버네티스는 각각 /api/v1 또는 /apis/rbac.authorization.k8s.io/v1alpha1 과 같은 **서로 다른 API 경로에서 여러 API 버전을 지원**한다.

- [네임스페이스](https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/namespaces/)

> 쿠버네티스는 동일한 물리 클러스터를 기반으로 하는 여러 가상 클러스터를 지원한다. 이런 가상 클러스터를 네임스페이스라고 한다.
>
> 네임스페이스는 여러 개의 팀이나, 프로젝트에 걸쳐서 많은 사용자가 있는 환경에서 사용하도록 만들어졌다. 사용자가 거의 없거나, 수 십명 정도가 되는 경우에는 네임스페이스를 전혀 고려할 필요가 없다. 네임스페이스가 제공하는 기능이 필요할 때 사용하도록 하자.

#### 쿠버네티스 실습

다음 글을 참고하였다.

- [오케스트레이션](https://docs.docker.com/get-started/orchestration/)
- [Kubernetes에 배포](https://docs.docker.com/get-started/kube-deploy/)
- [튜토리얼](https://kubernetes.io/ko/docs/tutorials/)
- [kubectl 치트시트](https://kubernetes.io/ko/docs/reference/kubectl/cheatsheet/)

윈도우에서는 도커 데스크톱을 쓰면 바로 시작해볼 수 있다. 일단 윈도우에서 해보자.

##### 활성화

우선 도커 데스크탑 설정에서 쿠버네티스를 활성화해준다. 설정화면에서 Enable kubernetes에 체크 후 Appy and Restart 버튼을 눌러주면 된다. 다운로드 및 설치가 진행되는 동안 왼쪽 하단의 쿠버네티스 로고가 주황색으로 표시되고, 활성화가 끝나면 로고가 초록색으로 바뀐다.

```
아무리 기다려도 초록색으로 바뀌지 않고 'starting...' 무한 루프인 경우 KUBECONFIG 환경변수를 C:\Users\<사용자>\.kube\config로 설정한 후 도커 데스크탑을 공장 초기화(벌레모양 아이콘) 해보자.
```

포드를 생성하고 실행해본다.

```powershell
# pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo
spec:
  containers:
  - name: testpod
    image: alpine:3.5
    command: ["ping", "8.8.8.8"]

> kubectl apply -f pod.yaml # 포드 실행
> kubectl get pods # 포드 실행 확인
> kubectl logs demo # 로그 확인
> kubectl delete -f pod.yml # 포드 분해
```

##### 쿠버네티스에 배포

디플로이먼트와 서비스를 다루어본다.

```powershell
# bb.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bb-demo
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      bb: web
  template:
    metadata:
      labels:
        bb: web
    spec:
      containers:
      - name: bb-site
        image: <도커아이디>/example-nodejs:1.1
---
apiVersion: v1
kind: Service
metadata:
  name: bb-entrypoint
  namespace: default
spec:
  type: NodePort
  selector:
    bb: web
  ports:
  - port: 8080
    targetPort: 8080
    nodePort: 30001

> kubectl apply -f bb.yaml
> kubectl get deployments
> kubectl get services
> kubectl delete -f bb.yaml
```

브라우저에서 localhost:30001로 접속하면 앱을 볼 수 있다.

##### 미니큐브

미니큐브를 [설치](https://minikube.sigs.k8s.io/docs/start/)해보자(도커 쿠버네티스 활성화 상태에서 설치함). 미니큐브를 사용하면 대시보드에서 워크로드, 서비스 등을 한 눈에 볼 수 있어 편리하다. 설치가 끝나면 minikube 클러스터를 만들고 대시보드를 띄워보자.

```powershell
minikube start
minikube dashboard
```

참고로 minikube start 전과 후를 비교해면 대략 아래와 같이 docker-desktop 부분이 minikube로 바뀌어 있다.

```powershell
> kubectl get po -A
kube-system   coredns-f9fd979d6-bfh5c                  1/1     Running   4
kube-system   coredns-f9fd979d6-wdfh4                  1/1     Running   4
kube-system   etcd-docker-desktop                      1/1     Running   4
kube-system   kube-apiserver-docker-desktop            1/1     Running   4
kube-system   kube-controller-manager-docker-desktop   1/1     Running   4
kube-system   kube-proxy-ptbjx                         1/1     Running   4
kube-system   kube-scheduler-docker-desktop            1/1     Running   4
kube-system   storage-provisioner                      1/1     Running   4
kube-system   vpnkit-controller                        1/1     Running   4

> minikube start
> kubectl get po -A
kube-system            coredns-74ff55c5b-s7ckm                     1/1     Running   2
kube-system            etcd-minikube                               1/1     Running   2
kube-system            kube-apiserver-minikube                     1/1     Running   2
kube-system            kube-controller-manager-minikube            1/1     Running   2
kube-system            kube-proxy-mmkrg                            1/1     Running   2
kube-system            kube-scheduler-minikube                     1/1     Running   2
kube-system            metrics-server-56c4f8c9d6-h4k6s             1/1     Running   2
kube-system            storage-provisioner                         1/1     Running   4
kubernetes-dashboard   dashboard-metrics-scraper-f6647bd8c-bw4ss   1/1     Running   2
kubernetes-dashboard   kubernetes-dashboard-968bcb79-l5v9q         1/1     Running   2
```

클러스터 정보를 본다.

```powershell
> kubectl cluster-info
> kubectl get nodes
```

디플로이먼트를 생성해보자. 클러스터 위에 디플로이먼트를 생성하면 적절한 노드에 파드가 생성되어 애플리케이션 인스턴스 실행이 예약되고, 필요시 새 노드에 재예약하도록 클러스터 설정이 이루어진다. 장애 상황 등 발생시 다른 노드의 인스턴스로 교체되어 자동 복구된다. 그러나 현재는 노드가 하나 뿐이다.

```powershell
> kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 # 디플로이먼트 생성
> kubectl get deployments # 디플로이먼트 나열
> kubectl get pods # 파드 나열
> kubectl describe deployments # 디플로이먼트 상세
> kubectl describe pods # 파드 상세
> kubectl proxy # 프록시를 통해 외부에서 API로 직접 접근 허용(브라우저에서 접근)
> curl http://localhost:8001/api/v1/namespaces/default/pods/<파드이름>/proxy/ # API 사용
> kubectl logs <파드이름> # 컨테이너 로그 보기 - 파드에 컨테이너가 하나 뿐이면 파드 이름만으로 OK
> kubectl exec <파드이름> env # 컨테이너 환경변수 보기
> kubectl exec -ti <파드이름> bash # 컨테이너 bash 
> curl localhost:8080
> exit
```

서비스를 사용해 앱을 클러스터 외부로 노출해보자. 이제 브라우저에서 localhost:32443 으로 접속할 수 있다. 서비스를 지우면 외부에서는 접근할 수 없지만 여전히 내부에서는 여전히 앱이 실행 중이다.

```powershell
> kubectl expose deployment/kubernetes-bootcamp --type="NodePort" --port 8080
NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
kubernetes            ClusterIP   10.96.0.1      <none>        443/TCP          31h
kubernetes-bootcamp   NodePort    10.100.78.85   <none>        8080:32443/TCP   6s

> kubectl describe deployments # 레이블을 알 수 있다.
> kubectl get pods -l <레이블> # 레이블을 사용해 파드 나열
> kubectl get services -l <레이블> # 레이블을 사용해 서비스 나열
> kubectl label pod <파드이름> <레이블> # 파드의 레이블을 설정
> kubectl delete service -l <레이블> # 레이블을 사용해 서비스를 삭제
> kubectl exec -ti <파드이름> curl localhost:8080 # 내부에서는 여전히 앱이 실행 중
```

- [쿠버네티스 디플로이먼트](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/)

> 일단 쿠버네티스 클러스터를 구동시키면, 그 위에 컨테이너화된 애플리케이션을 배포할 수 있다. 그러기 위해서, 쿠버네티스 **디플로이먼트** 설정을 만들어야 한다. 디플로이먼트는 쿠버네티스가 애플리케이션의 인스턴스를 어떻게 생성하고 업데이트해야 하는지를 지시한다. 디플로이먼트가 만들어지면, 쿠버네티스 컨트롤 플레인이 해당 디플로이먼트에 포함된 애플리케이션 인스턴스가 클러스터의 개별 노드에서 실행되도록 스케줄한다.
>
> 애플리케이션 인스턴스가 생성되면, 쿠버네티스 디플로이먼트 컨트롤러는 지속적으로 이들 인스턴스를 모니터링한다. 인스턴스를 구동 중인 노드가 다운되거나 삭제되면, 디플로이먼트 컨트롤러가 인스턴스를 클러스터 내부의 다른 노드의 인스턴스로 교체시켜준다.**이렇게 머신의 장애나 정비에 대응할 수 있는 자동 복구(self-healing) 메커니즘을 제공한다.**
>
> 오케스트레이션 기능이 없던 환경에서는, 설치 스크립트가 애플리케이션을 시작하는데 종종 사용되곤 했지만, 머신의 장애가 발생한 경우 복구를 해주지는 않았다. 쿠버네티스 디플로이먼트는 애플리케이션 인스턴스를 생성해주고 여러 노드에 걸쳐서 지속적으로 인스턴스가 구동되도록 하는 두 가지를 모두 하기 때문에 애플리케이션 관리를 위한 접근법에서 근본적인 차이를 가져다준다.
>
> **Kubectl**이라는 쿠버네티스 CLI를 통해 디플로이먼트를 생성하고 관리할 수 있다. Kubectl은 클러스터와 상호 작용하기 위해 쿠버네티스 API를 사용한다. 이 모듈에서는, 쿠버네티스 클러스터 상에 애플리케이션을 구동시키는 디플로이먼트를 생성하기 위해 필요한 가장 일반적인 Kubectl 명령어를 배우게 된다.

> 디플로이먼트를 생성할 때, 애플리케이션에 대한 컨테이너 이미지와 구동시키고자 하는 복제 수를 지정해야 한다. 디플로이먼트를 업데이트해서 이런 정보를 나중에 변경할 수 있다. 모듈 5와 6의 부트캠프에서 어떻게 스케일하고 업데이트하는지에 대해 다룬다. [출처](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/)

- [클러스터](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/)
- [쿠버네티스 파드](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/explore/explore-intro/)

> 모듈 2에서 배포를 생성했을 때, 쿠버네티스는 여러분의 애플리케이션 인스턴스에 **파드**를 생성했다. 파드는 하나 또는 그 이상의 애플리케이션 컨테이너 (도커와 같은)들의 그룹을 나타내는 쿠버네티스의 추상적 개념으로 일부는 컨테이너에 대한 자원을 공유한다. 그 자원은 다음을 포함한다:
>
> - 볼륨과 같은, 공유 스토리지
> - 클러스터 IP 주소와 같은, 네트워킹
> - 컨테이너 이미지 버전 또는 사용할 특정 포트와 같이, 각 컨테이너가 동작하는 방식에 대한 정보
>
> 파드는 특유한 "로컬호스트" 애플리케이션 모형을 만들어. 상대적으로 밀접하게 결합되어진 상이한 애플리케이션 컨테이너들을 수용할 수 있다. 가령, 파드는 Node.js 앱과 더불어 Node.js 웹서버에 의해 발행되는 데이터를 공급하는 상이한 컨테이너를 함께 수용할 수 있다. 파드 내 컨테이너는 IP 주소, 그리고 포트 스페이스를 공유하고 항상 함께 위치하고 함께 스케쥴링 되고 동일 노드 상의 컨텍스트를 공유하면서 동작한다.
>
> 파드는 쿠버네티스 플랫폼 상에서 최소 단위가 된다. 우리가 쿠버네티스에서 배포를 생성할 때, 그 배포는 컨테이너 내부에서 컨테이너와 함께 파드를 생성한다. 각 파드는 스케쥴 되어진 노드에게 묶여지게 된다. 그리고 (재구동 정책에 따라) 소멸되거나 삭제되기 전까지 그 노드에 유지된다. 노드에 실패가 발생할 경우, 클러스터 내에 가용한 다른 노드들을 대상으로 스케쥴되어진다.

- [노드](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/explore/explore-intro/)

> 파드는 언제나 **노드** 상에서 동작한다. 노드는 쿠버네티스에서 워커 머신을 말하며 클러스터에 따라 가상 또는 물리 머신일 수 있다. 각 노드는 마스터에 의해 관리된다. 하나의 노드는 여러 개의 파드를 가질 수 있고, 쿠버네티스 마스터는 클러스터 내 노드를 통해서 파드에 대한 스케쥴링을 자동으로 처리한다.
>
> 모든 쿠버네티스 노드는 최소한 다음과 같이 동작한다.
>
> - Kubelet은, 쿠버네티스 마스터와 노드 간 통신을 책임지는 프로세스이며, 하나의 머신 상에서 동작하는 파드와 컨테이너를 관리한다.
> - 컨테이너 런타임(도커와 같은)은 레지스트리에서 컨테이너 이미지를 가져와 묶여 있는 것을 풀고 애플리케이션을 동작시키는 책임을 맡는다.

- [서비스](https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/expose/expose-intro/)

> 쿠버네티스 파드들 은 언젠가는 죽게된다. 실제 파드들은 생명주기를 갖는다. 워커 노드가 죽으면, 노드 상에서 동작하는 파드들 또한 종료된다. 레플리카셋(ReplicaSet)은 여러분의 애플리케이션이 지속적으로 동작할 수 있도록 새로운 파드들의 생성을 통해 동적으로 클러스터를 미리 지정해 둔 상태로 되돌려 줄 수도 있다. 또 다른 예시로서, 3개의 복제본을 갖는 이미지 처리용 백엔드를 고려해 보자. 그 복제본들은 교체 가능한 상태이다. 그래서 프론트엔드 시스템은 하나의 파드가 소멸되어 재생성이 되더라도, 백엔드 복제본들에 의한 영향을 받아서는 안된다. 즉, 동일 노드 상의 파드들이라 할지라도, 쿠버네티스 클러스터 내 각 파드는 유일한 IP 주소를 가지며, 여러분의 애플리케이션들이 지속적으로 기능할 수 있도록 파드들 속에서 발생하는 변화에 대해 자동으로 조정해 줄 방법이 있어야 한다.
>
> 쿠버네티스에서 서비스는 하나의 논리적인 파드 셋과 그 파드들에 접근할 수 있는 정책을 정의하는 추상적 개념이다. 서비스는 종속적인 파드들 사이를 느슨하게 결합되도록 해준다. 서비스는 모든 쿠버네티스 오브젝트들과 같이 YAML (보다 선호하는) 또는 JSON을 이용하여 정의된다. 서비스가 대상으로 하는 파드 셋은 보통 LabelSelector에 의해 결정된다 (여러분이 왜 스펙에 selector가 포함되지 않은 서비스를 필요로 하게 될 수도 있는지에 대해 아래에서 확인해 보자).
>
> 비록 각 파드들이 고유의 IP를 갖고 있기는 하지만, 그 IP들은 서비스의 도움없이 클러스터 외부로 노출되어질 수 없다. 서비스들은 여러분의 애플리케이션들에게 트래픽이 실릴 수 있도록 허용해준다. 서비스들은 ServiceSpec에서 type을 지정함으로써 다양한 방식들로 노출시킬 수 있다:
>
> - ClusterIP (기본값) - 클러스터 내에서 내부 IP 에 대해 서비스를 노출해준다. 이 방식은 오직 클러스터 내에서만 서비스가 접근될 수 있도록 해준다.
> - NodePort - NAT가 이용되는 클러스터 내에서 각각 선택된 노드들의 동일한 포트에 서비스를 노출시켜준다. :를 이용하여 클러스터 외부로부터 서비스가 접근할 수 있도록 해준다. ClusterIP의 상위 집합이다.
> - LoadBalancer - (지원 가능한 경우) 기존 클라우드에서 외부용 로드밸런서를 생성하고 서비스에 고정된 공인 IP를 할당해준다. NodePort의 상위 집합이다.
> - ExternalName - CNAME 레코드 및 값을 반환함으로써 서비스를 externalName 필드의 내용(예를 들면, foo.bar.example.com)에 매핑한다. 어떠한 종류의 프록시도 설정되지 않는다. 이 방식은 kube-dns v1.7 이상 또는 CoreDNS 버전 0.0.8 이상을 필요로 한다.
>
> 다른 서비스 타입들에 대한 추가 정보는 소스 IP 이용하기 튜토리얼에서 확인 가능하다. 또한 서비스들로 애플리케이션에 접속하기도 참고해 보자.
>
> 부가적으로, spec에 selector를 정의하지 않고 말아넣은 서비스들의 몇 가지 유즈케이스들이 있음을 주의하자. selector 없이 생성된 서비스는 상응하는 엔드포인트 오브젝트들 또한 생성하지 않는다. 이로써 사용자들로 하여금 하나의 서비스를 특정한 엔드포인트에 매핑 시킬수 있도록 해준다. selector를 생략하게 되는 또 다른 가능성은 여러분이 type: ExternalName을 이용하겠다고 확고하게 의도하는 경우이다.

> 서비스는 파드 셋에 걸쳐서 트래픽을 라우트한다. 여러분의 애플리케이션에 영향을 주지 않으면서 쿠버네티스에서 파드들이 죽게도 하고, 복제가 되게도 해주는 추상적 개념이다. 종속적인 파드들 사이에서의 디스커버리와 라우팅은 (하나의 애플리케이션에서 프로트엔드와 백엔드 컴포넌트와 같은) 쿠버네티스 서비스들에 의해 처리된다.
>
> 서비스는 쿠버네티스의 객체들에 대해 논리 연산을 허용해주는 기본 그룹핑 단위인, 레이블과 셀렉터를 이용하여 파드 셋과 매치시킨다. 레이블은 오브젝트들에 붙여진 키/밸류 쌍으로 다양한 방식으로 이용 가능하다:
>
> - 개발, 테스트, 그리고 상용환경에 대한 객체들의 지정
> - 임베디드된 버전 태그들
> - 태그들을 이용하는 객체들에 대한 분류

#### 도커 스웜

다음 글을 참고하였다.

- [Swarm에 배포](https://docs.docker.com/get-started/swarm-deploy/)
- [Swarm 모드 시작](https://docs.microsoft.com/ko-kr/virtualization/windowscontainers/manage-containers/swarm-mode)