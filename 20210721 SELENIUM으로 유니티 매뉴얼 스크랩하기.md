---
title: "SELENIUM으로 유니티 매뉴얼 스크랩하기"
---

# SELENIUM으로 유니티 매뉴얼 스크랩하기

노트의 퍼포먼스가 어느정도인지 보기 위해 유니티 매뉴얼 약 1000개 항목을 스크랩하여 트리에 담아보았다.



```python
from selenium import webdriver
from selenium.webdriver import ActionChains
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
import bs4
from bs4 import UnicodeDammit
import os, sys, time

def expand(link):

	browser.execute_script("""
		$('.toc').mCustomScrollbar('scrollTo', 9000);
	""")
	
	item = browser.find_element_by_link_text(link)
	arrow = browser.find_element_by_xpath("//a[normalize-space(text())='"+link+"']/preceding-sibling::div")
	arrow.click()
	
	browser.execute_script("""
		$('.toc').mCustomScrollbar('scrollTo', 9000);
	""")
	
	child = browser.find_element_by_xpath("//a[normalize-space(text())='"+link+"']/following-sibling::ul")
	
	list = child.text.split('\n')
	for link in list:
		item = browser.find_element_by_link_text(link)
		item = browser.find_element_by_xpath("//a[normalize-space(text())='"+link+"']")
		arrow = browser.find_element_by_xpath("//a[normalize-space(text())='"+link+"']/preceding-sibling::div")
		if 'arrow' in arrow.get_attribute('class'):
			try:
				expand(link)
			except:
				print(item.text)
	
	browser.execute_script("""
		$('.toc').mCustomScrollbar('scrollTo', 9000);
	""")

def mine():
	startingpoint = "http://docs.unity3d.com/kr/current/Manual/UnityManual.html"
	browser = webdriver.Chrome()
	browser.get(startingpoint)

	toc = browser.find_element_by_css_selector("#sidebar .mCSB_container>ul")
	list = toc.text.split('\n')
	for link in list:
		expand(link)
	
	browser.quit()

def scrap():
	f = open("3_href.txt", 'r')
	while True:
		line = f.readline().strip()
		if not line: break

		# requests에서 인코딩을 설정해준다
		r = requests.get("http://docs.unity3d.com/kr/current/Manual/" + line)
		r.encoding = 'utf-8'
	
		# 뷰티풀수프에서는 무조건 utf-8로 출력된다
		soup = bs4.BeautifulSoup(r.text, "html.parser")
		selector = '.content .section'
		html = soup.select(selector)
		#html = html[0].get_text()
		html = html[0].prettify()
	
		f2 = open("unitymanual/"+line, 'w', encoding='UTF-8')
		f2.write(html)
		f2.close()
	
	f.close()

def refine():
	for (path, dir, files) in os.walk("unitymanual"):
		for filename in files:
			f = open('unitymanual\\' + filename, 'r', encoding='UTF-8')
			lines = f.readlines()
			f.close()

			f = open('unitymanual\\' + filename, 'w', encoding='UTF-8')
			replaceable = False
			#f.write('<div>\n')
			for line in lines:
				if replaceable:
					if "../uploads" in line:
						line = line.replace("../uploads", "http://docs.unity3d.com/kr/current/uploads")
					if '<a href="http' in line:
						line = line.replace('<a href="http', '<a contenteditable="false" target="_blank" href="http')
					elif '<a href="' in line:
						line = line.replace('<a href="', '<a contenteditable="false" target="_blank" href="http://docs.unity3d.com/kr/current/Manual/')
	
					if '<div class="nextprev clear">' in line:
						replaceable = False
						continue
	
					f.write(line)
				else:
					line = line.strip()
					if line == '<!--EndSwitchLink-->' or line == '<div class="clear">' or line == '<p>' or line == '<h2>':
						f.write(line)
						replaceable = True
			f.close()

def print_list(lst, level=0):
    for l in lst[0:]:
        if type(l) is list:
            print_list(l, level + 1)
        else:
            print('    ' * level + '+---' + l)

def post():
	#startingpoint = "http://localhost:8000/accounts/login"
	#browser = webdriver.Chrome()
	#browser.get(startingpoint)
	#browser.find_element_by_css_selector("#id_username").send_keys('rebolation')
	#browser.find_element_by_css_selector("#id_password").send_keys('rebo1305')
	#browser.find_element_by_css_selector("input[type=submit]").click()
	#time.sleep(2)
	#browser.find_element_by_css_selector("#jstree>ul>li:last-child").click()

	import psycopg2
	conn_string = "host='localhost' dbname ='springnote' user='springnote' password='1234'"
	conn = psycopg2.connect(conn_string)
	curs= conn.cursor()
	#query = "SELECT * FROM note_note"
	#curs.execute(query)
	#result = curs.fetchall()
	#print(result)
	
	f = open("4_tree.txt", 'r', encoding='UTF-8')
	
	notes = []
	id = 0
	order = 0
	parent = 0
	
	parents = []
	orders = [0]
	
	lastdepth = 0
	lastnoteid = 0
	
	lastinsertedid = 0
	
	while True:
		line = f.readline()
		if not line: break
	
		id = id + 1
		text = line.strip().split(" : ")[1]
		html = line.strip().split(" : ")[0]
		orders[-1] = orders[-1] + 1
	
		depth = line.count('\t') // 2
	
		if depth == 0: #뎁스가 0이면 최상위
			parent = 0
			parents.append(id)
			orders = orders[0:1]
			order = orders[-1]
		else:
			if depth > lastdepth: #뎁스가 0보다 크고 마지막 노트의 뎁스보다 크면(자식)
				parents.append(lastnoteid)
				parent = parents[-1]
				order = 1
				orders.append(order)
			if depth == lastdepth: #뎁스가 0보다 크고 마지막 노트의 뎁스와 같으면(형제)
				parent = parents[-1]
				order = orders[-1]
			if depth < lastdepth: #뎁스가 0보다 크고 마지막 노트의 뎁스보다 작으면(마지막 노트의 부모의 형제)
				for i in range(1, lastdepth - depth + 1):
					parents.pop()
					orders.pop()
				parent = parents[-1]
				order = orders[-1]
	
		if html == "#":
			content = ''
		else:
			f2 = open('unitymanual\\' + html, 'r', encoding='UTF-8')
			content = f2.read()
			f2.close()
	
		note = [id, parent, order, content, text]
		notes.append(note)
	
		#DB insert
		order = int(order)
		regdate = '2016-05-12 13:03:11.5'
		author_id = 2
		parent_id = int(parent)
		if parent_id == 0:
			parent_id = None
		completed = False
	
		query =  """
			INSERT INTO note_note ("order", text, content, regdate, author_id, parent_id, completed ) 
			VALUES (%s, %s, %s, %s, %s, %s, %s) RETURNING id;
		"""
		data = [order, text, content, regdate, author_id, parent_id, completed]
		curs.execute(query, data)
		lastinsertedid = curs.fetchone()[0]
	
		conn.commit()
	
		lastnoteid = lastinsertedid
		lastdepth = depth
	
		#print(lastnoteid, note[1], note[4])
	
	f.close()
	
	#for note in notes:
		#print(note)





#mine()
#scrap()
refine()
#post()
```

